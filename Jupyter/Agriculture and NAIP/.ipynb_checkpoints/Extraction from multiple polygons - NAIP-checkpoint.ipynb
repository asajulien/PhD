{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e50647",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Look into object-based classification - this might be the best way \n",
    "#https://gsp.humboldt.edu/olm/Courses/GSP_216/lessons/Classification/object.html\n",
    "#https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/27_cell_classification/sklearn_object_classification.html\n",
    "\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "from IPython.display import display\n",
    "import ee\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb0e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06db615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the region of interest for Georgia and Iowa\n",
    "iowa = geemap.shp_to_ee('F:/US states/iowa.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f23c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = ee.ImageCollection('USGS/3DEP/1m') \\\n",
    "    .filterBounds(iowa) \\\n",
    "    .mosaic()\n",
    "\n",
    "dem_vis = {\n",
    "  'min': 0,\n",
    "  'max': 3000,\n",
    "  'palette': [\n",
    "    '3ae237', 'b5e22e', 'd6e21f', 'fff705', 'ffd611', 'ffb613', 'ff8b13',\n",
    "    'ff6e08', 'ff500d', 'ff0000', 'de0101', 'c21301', '0602ff', '235cb1',\n",
    "    '307ef3', '269db1', '30c8e2', '32d3ef', '3be285', '3ff38f', '86e26f'\n",
    "  ]\n",
    "}\n",
    "\n",
    "hillshade_iowa = ee.Terrain.hillshade(dem.select('elevation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4229ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add date to image\n",
    "def addDate(image):\n",
    "    img_date = ee.Date(image.date())\n",
    "    img_date = ee.Number.parse(img_date.format('YYYYMMdd'))\n",
    "    return image.addBands(ee.Image(img_date).rename('imagedate').toInt())\n",
    "\n",
    "def addNDVI(image):\n",
    "    ndvi = ee.Image(0).expression(\n",
    "        '((NIR-RED)/(NIR+RED))', {\n",
    "            'NIR': image.select('N'),\n",
    "            'RED': image.select('R')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(ndvi.rename('ndvi'))\n",
    "\n",
    "\n",
    "def addNDWI(image):\n",
    "    ndwi = ee.Image(0).expression(\n",
    "        '((GREEN-NIR)/(GREEN+NIR))', {\n",
    "            'NIR': image.select('N'),\n",
    "            'GREEN': image.select('G')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(ndwi.rename('ndwi'))\n",
    "\n",
    "\n",
    "# NAIP: Define the date range for Iowa imagery (2010) AND MOSAIC \n",
    "iowa_mosaic_2010 = ee.ImageCollection('USDA/NAIP/DOQQ') \\\n",
    "    .filterBounds(iowa) \\\n",
    "    .filterDate('2010-01-01', '2010-12-31') \\\n",
    "    .map(addDate) \\\n",
    "    .mosaic() \\\n",
    "    .addBands(dem.select('elevation'))\n",
    "\n",
    "iowa_mosaic_addedbands = ee.ImageCollection('USDA/NAIP/DOQQ') \\\n",
    "    .filterBounds(iowa) \\\n",
    "    .filterDate('2010-01-01', '2010-12-31') \\\n",
    "    .map(addNDVI) \\\n",
    "    .map(addNDWI) \\\n",
    "    .map(addDate) \\\n",
    "    .mosaic() \\\n",
    "    .addBands(dem.select('elevation'))\n",
    "\n",
    "'''\n",
    "Adding the ndvi and ndwi bands messes up the raster extraction, at least for farmland_rasterextraction.\n",
    "Not sure why, but ends up with less data than it should.\n",
    "'''\n",
    "\n",
    "\n",
    "# NLCD: create farmland buffer. Only data available is 2021 and 2019.\n",
    "nlcd_iowa = ee.ImageCollection(\"USGS/NLCD_RELEASES/2021_REL/NLCD\") \\\n",
    "    .filterBounds(iowa) \\\n",
    "    .filterDate('2001-01-01', '2021-12-31') \\\n",
    "    .select('landcover') \\\n",
    "    .mosaic() \\\n",
    "    .clip(iowa)\n",
    "\n",
    "#Create farmland mask:\n",
    "# nlcd_mask = nlcd_iowa.eq(71).Or(nlcd_iowa.eq(81)).Or(nlcd_iowa.eq(82)) ##improved below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1ba65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract values from features\n",
    "#Note: return feature.limit(5000) added to get the function to work for this large dataset - max per polygon\n",
    "##UPDATE: FEATURE LIMIT SAMPLE SIZE must be BALANCED\n",
    "\n",
    "# Function to extract values from features within buffer polygons\n",
    "def dam_rasterExtraction_within_buffer(image, buffer_polygon):\n",
    "    dam_clip_within_buffer = dam_clip.filterBounds(buffer_polygon.geometry())\n",
    "    \n",
    "    feature = image.sampleRegions(\n",
    "        collection=dam_clip_within_buffer,\n",
    "        scale=1, # Assuming NAIP imagery resolution\n",
    "        geometries=True)\n",
    "    \n",
    "    return feature.limit(1000)\n",
    "\n",
    "\n",
    "\n",
    "def terrace_rasterExtraction_within_buffer(image, buffer_polygon):\n",
    "    terrace_clip_within_buffer = terrace_clip.filterBounds(buffer_polygon.geometry())\n",
    "    feature = image.sampleRegions(\n",
    "        collection=terrace_clip_within_buffer,\n",
    "        scale=1, # Assuming NAIP imagery resolution\n",
    "        geometries=True\n",
    "    )\n",
    "    \n",
    "    elev_values = dem.sampleRegions(\n",
    "        collection=terrace_clip_within_buffer,\n",
    "        scale=1,\n",
    "        geometries=True\n",
    "    )\n",
    "\n",
    "    return feature.limit(1000)\n",
    "\n",
    "\n",
    "\n",
    "def basin_rasterExtraction_within_buffer(image, buffer_polygon):\n",
    "    basin_clip_within_buffer = basin_clip.filterBounds(buffer_polygon.geometry())\n",
    "    feature = image.sampleRegions(\n",
    "        collection=basin_clip_within_buffer,\n",
    "        scale=1, # Assuming NAIP imagery resolution\n",
    "        geometries=True\n",
    "    )\n",
    "    \n",
    "    elev_values = dem.sampleRegions(\n",
    "        collection=basin_clip_within_buffer,\n",
    "        scale=1,\n",
    "        geometries=True\n",
    "    )\n",
    "    \n",
    "    return feature.limit(1000)\n",
    "\n",
    "\n",
    "\n",
    "def grassed_rasterExtraction_within_buffer(image, buffer_polygon):\n",
    "    grassed_clip_within_buffer = grassed_clip.filterBounds(buffer_polygon.geometry())\n",
    "    feature = image.sampleRegions(\n",
    "        collection=grassed_clip_within_buffer,\n",
    "        scale=1, # Assuming NAIP imagery resolution\n",
    "        geometries=True\n",
    "    )\n",
    "    \n",
    "    return feature.limit(1000)\n",
    "\n",
    "\n",
    "\n",
    "def contour_rasterExtraction_within_buffer(image, buffer_polygon):\n",
    "    contour_clip_within_buffer = contour_clip.filterBounds(buffer_polygon.geometry())\n",
    "    feature = image.sampleRegions(\n",
    "        collection=contour_clip_within_buffer,\n",
    "        scale=1, # Assuming NAIP imagery resolution\n",
    "        geometries=True\n",
    "    )\n",
    "    \n",
    "    return feature.limit(1000)\n",
    "\n",
    "\n",
    "\n",
    "def strip_rasterExtraction_within_buffer(image, buffer_polygon):\n",
    "    strip_clip_within_buffer = strip_clip.filterBounds(buffer_polygon.geometry())\n",
    "    feature = image.sampleRegions(\n",
    "        collection=strip_clip_within_buffer,\n",
    "        scale=1, # Assuming NAIP imagery resolution\n",
    "        geometries=True\n",
    "    )\n",
    "    \n",
    "    elev_values = dem.sampleRegions(\n",
    "        collection=strip_clip_within_buffer,\n",
    "        scale=1,\n",
    "        geometries=True\n",
    "    )\n",
    "    \n",
    "    return feature.limit(1000)\n",
    "\n",
    "\n",
    "\n",
    "#Dummy farm variable using NLCD - NOTE THE DIFFERENT FORMAT IN HOW THE FUNCTION WORKS\n",
    "def farm_rasterExtraction_within_buffer(image, region):\n",
    "    feature = image.sampleRegions(\n",
    "        collection=region,\n",
    "        scale=1, # Assuming NAIP imagery resolution - NLCD is 30 m though\n",
    "        geometries=True\n",
    "    )\n",
    "    \n",
    "    return feature.limit(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f7b9b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random buffer zones - 100 of them. NOTE: in earlier version, _buffer was used instead of _clip\n",
    "\n",
    "# buffer_points = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_areas/buffer.shp')\n",
    "buffer_points = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_areas/buffer2.shp') #no overlaps\n",
    "\n",
    "# contour_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips/contour_buffer.shp')\n",
    "# grassed_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips/grassed_buffer.shp')\n",
    "# dam_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips/dam_buffer.shp')\n",
    "# strip_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips/strip_buffer.shp')\n",
    "# terrace_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips/terrace_buffer.shp')\n",
    "# basin_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips/basin_buffer.shp')\n",
    "\n",
    "#Switched to bufferclips2 folder - no overlaps, 100 polygons\n",
    "contour_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips2/contour_buffer.shp')\n",
    "grassed_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips2/grassed_buffer.shp')\n",
    "dam_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips2/dam_buffer.shp')\n",
    "strip_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips2/strip_buffer.shp')\n",
    "terrace_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips2/terrace_buffer.shp')\n",
    "basin_clip = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/buffer_clips2/basin_buffer.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30c4b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask for BMP clips:\n",
    "\n",
    "def maskInside(image, geometry):\n",
    "    mask = ee.Image.constant(1).clip(geometry).mask().Not()\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "def maskFarmland(image):\n",
    "    mask = image.eq(71).Or(image.eq(81)).Or(image.eq(82))\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "\n",
    "# Combine all feature geometries into a single multipolygon\n",
    "all_features = contour_clip.merge(grassed_clip).merge(dam_clip).merge(strip_clip).merge(terrace_clip).merge(basin_clip)\n",
    "all_multipolygon = all_features.geometry()\n",
    "\n",
    "# Apply the  mask to the NLCD image\n",
    "# nlcd_filtered = maskInside(nlcd_mask, all_multipolygon)\n",
    "\n",
    "nlcd_filtered = maskInside(maskFarmland(nlcd_iowa), all_multipolygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6afeecbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a map\n",
    "Map = geemap.Map(center=[40.6, -94], zoom=10)\n",
    "\n",
    "# Map.addLayer(nlcd_iowa,{},'NLCD')\n",
    "# Map.addLayer(nlcd_mask, {}, 'NLCD Mask')\n",
    "\n",
    "iowa_masked = iowa_mosaic_2010.updateMask(nlcd_filtered)\n",
    "\n",
    "# Map.addLayer(nlcd_filtered, {}, 'Filtered NLCD')\n",
    "\n",
    "# Map.addLayer(dem, dem_vis, 'elevation')\n",
    "# Map.addLayer(hillshade_iowa)\n",
    "\n",
    "Map.addLayer(iowa_masked, {}, 'Masked')\n",
    "\n",
    "Map.addLayer(buffer_points, {}, 'buffer points')\n",
    "\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "730470f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert buffer polygon shapefile into list of all polygon features\n",
    "buffer_list = buffer_points.toList(buffer_points.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc462a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dam\n",
    "# Initialize an empty list to store the results\n",
    "result_list = []\n",
    "\n",
    "# Iterate over each buffer polygon and extract raster values within each buffer\n",
    "for i in range(buffer_list.size().getInfo()):\n",
    "    try:\n",
    "        buffer_polygon = ee.Feature(buffer_list.get(i))\n",
    "        result = geemap.ee_to_pandas(dam_rasterExtraction_within_buffer(iowa_mosaic_2010, buffer_polygon))\n",
    "        result_list.append(result)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Merge the results into a single dataframe\n",
    "dam_mosaic = pd.concat(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd47926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam_mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2384a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Terrace\n",
    "# Initialize an empty list to store the results\n",
    "result_list = []\n",
    "\n",
    "# Iterate over each buffer polygon and extract raster values within each buffer\n",
    "for i in range(buffer_list.size().getInfo()):\n",
    "    try:\n",
    "        buffer_polygon = ee.Feature(buffer_list.get(i))\n",
    "        result = geemap.ee_to_pandas(terrace_rasterExtraction_within_buffer(iowa_mosaic_2010, buffer_polygon))\n",
    "        result_list.append(result)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Merge the results into a single dataframe\n",
    "terrace_mosaic = pd.concat(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9da77ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basin\n",
    "# Initialize an empty list to store the results\n",
    "result_list = []\n",
    "\n",
    "# Iterate over each buffer polygon and extract raster values within each buffer\n",
    "for i in range(buffer_list.size().getInfo()):\n",
    "    try:\n",
    "        buffer_polygon = ee.Feature(buffer_list.get(i))\n",
    "        result = geemap.ee_to_pandas(basin_rasterExtraction_within_buffer(iowa_mosaic_2010, buffer_polygon))\n",
    "        result_list.append(result)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Merge the results into a single dataframe\n",
    "basin_mosaic = pd.concat(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "455adf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grassed\n",
    "# Initialize an empty list to store the results\n",
    "result_list = []\n",
    "\n",
    "# Iterate over each buffer polygon and extract raster values within each buffer\n",
    "for i in range(buffer_list.size().getInfo()):\n",
    "    try:\n",
    "        buffer_polygon = ee.Feature(buffer_list.get(i))\n",
    "        result = geemap.ee_to_pandas(grassed_rasterExtraction_within_buffer(iowa_mosaic_2010, buffer_polygon))\n",
    "        result_list.append(result)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Merge the results into a single dataframe\n",
    "grassed_mosaic = pd.concat(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "41700b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contour\n",
    "# Initialize an empty list to store the results\n",
    "result_list = []\n",
    "\n",
    "# Iterate over each buffer polygon and extract raster values within each buffer\n",
    "for i in range(buffer_list.size().getInfo()):\n",
    "    try:\n",
    "        buffer_polygon = ee.Feature(buffer_list.get(i))\n",
    "        result = geemap.ee_to_pandas(contour_rasterExtraction_within_buffer(iowa_mosaic_2010, buffer_polygon))\n",
    "        result_list.append(result)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Merge the results into a single dataframe\n",
    "contour_mosaic = pd.concat(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3977b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip\n",
    "# Initialize an empty list to store the results\n",
    "result_list = []\n",
    "\n",
    "# Iterate over each buffer polygon and extract raster values within each buffer\n",
    "for i in range(buffer_list.size().getInfo()):\n",
    "    try:\n",
    "        buffer_polygon = ee.Feature(buffer_list.get(i))\n",
    "        result = geemap.ee_to_pandas(strip_rasterExtraction_within_buffer(iowa_mosaic_2010, buffer_polygon))\n",
    "        result_list.append(result)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Merge the results into a single dataframe\n",
    "strip_mosaic = pd.concat(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7d2b103b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>ORIG_FID</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>BUFF_DIST</th>\n",
       "      <th>CID</th>\n",
       "      <th>elevation</th>\n",
       "      <th>R</th>\n",
       "      <th>B</th>\n",
       "      <th>imagedate</th>\n",
       "      <th>G</th>\n",
       "      <th>N</th>\n",
       "      <th>PRACTICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067156</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>366.786072</td>\n",
       "      <td>109</td>\n",
       "      <td>100</td>\n",
       "      <td>20100914</td>\n",
       "      <td>105</td>\n",
       "      <td>123</td>\n",
       "      <td>Farmland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067156</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>366.804016</td>\n",
       "      <td>102</td>\n",
       "      <td>100</td>\n",
       "      <td>20100914</td>\n",
       "      <td>87</td>\n",
       "      <td>109</td>\n",
       "      <td>Farmland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067156</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>366.785278</td>\n",
       "      <td>122</td>\n",
       "      <td>100</td>\n",
       "      <td>20100914</td>\n",
       "      <td>118</td>\n",
       "      <td>134</td>\n",
       "      <td>Farmland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.067156</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>366.795105</td>\n",
       "      <td>113</td>\n",
       "      <td>100</td>\n",
       "      <td>20100914</td>\n",
       "      <td>118</td>\n",
       "      <td>122</td>\n",
       "      <td>Farmland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067156</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>366.795105</td>\n",
       "      <td>113</td>\n",
       "      <td>100</td>\n",
       "      <td>20100914</td>\n",
       "      <td>118</td>\n",
       "      <td>122</td>\n",
       "      <td>Farmland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.066038</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>245.660461</td>\n",
       "      <td>84</td>\n",
       "      <td>108</td>\n",
       "      <td>20100813</td>\n",
       "      <td>112</td>\n",
       "      <td>134</td>\n",
       "      <td>Farmland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.066038</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>245.660461</td>\n",
       "      <td>84</td>\n",
       "      <td>108</td>\n",
       "      <td>20100813</td>\n",
       "      <td>112</td>\n",
       "      <td>134</td>\n",
       "      <td>Farmland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.066038</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>245.672089</td>\n",
       "      <td>99</td>\n",
       "      <td>112</td>\n",
       "      <td>20100813</td>\n",
       "      <td>123</td>\n",
       "      <td>149</td>\n",
       "      <td>Farmland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.066038</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>245.678116</td>\n",
       "      <td>91</td>\n",
       "      <td>109</td>\n",
       "      <td>20100813</td>\n",
       "      <td>112</td>\n",
       "      <td>130</td>\n",
       "      <td>Farmland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.066038</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>245.681931</td>\n",
       "      <td>95</td>\n",
       "      <td>113</td>\n",
       "      <td>20100813</td>\n",
       "      <td>121</td>\n",
       "      <td>141</td>\n",
       "      <td>Farmland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Shape_Leng  ORIG_FID  Shape_Area  BUFF_DIST  CID   elevation    R    B  \\\n",
       "0       0.067156         6    0.000346       1000    0  366.786072  109  100   \n",
       "1       0.067156         6    0.000346       1000    0  366.804016  102  100   \n",
       "2       0.067156         6    0.000346       1000    0  366.785278  122  100   \n",
       "3       0.067156         6    0.000346       1000    0  366.795105  113  100   \n",
       "4       0.067156         6    0.000346       1000    0  366.795105  113  100   \n",
       "...          ...       ...         ...        ...  ...         ...  ...  ...   \n",
       "4995    0.066038       100    0.000337       1000    0  245.660461   84  108   \n",
       "4996    0.066038       100    0.000337       1000    0  245.660461   84  108   \n",
       "4997    0.066038       100    0.000337       1000    0  245.672089   99  112   \n",
       "4998    0.066038       100    0.000337       1000    0  245.678116   91  109   \n",
       "4999    0.066038       100    0.000337       1000    0  245.681931   95  113   \n",
       "\n",
       "      imagedate    G    N  PRACTICE  \n",
       "0      20100914  105  123  Farmland  \n",
       "1      20100914   87  109  Farmland  \n",
       "2      20100914  118  134  Farmland  \n",
       "3      20100914  118  122  Farmland  \n",
       "4      20100914  118  122  Farmland  \n",
       "...         ...  ...  ...       ...  \n",
       "4995   20100813  112  134  Farmland  \n",
       "4996   20100813  112  134  Farmland  \n",
       "4997   20100813  123  149  Farmland  \n",
       "4998   20100813  112  130  Farmland  \n",
       "4999   20100813  121  141  Farmland  \n",
       "\n",
       "[245000 rows x 12 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NON-BMP FARMLAND - NOTE THE DIFFERENT SYNTAX\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "iowa_masked = iowa_mosaic_2010.updateMask(nlcd_filtered)\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# Iterate over each buffer polygon and extract raster values within each buffer\n",
    "for i in range(buffer_list.size().getInfo()):\n",
    "    try:\n",
    "        region = ee.Feature(buffer_list.get(i))\n",
    "        result = geemap.ee_to_pandas(farm_rasterExtraction_within_buffer(iowa_masked, region))\n",
    "        result_list.append(result)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Merge the results into a single dataframe\n",
    "farmland_mosaic = pd.concat(result_list)\n",
    "\n",
    "farmland_mosaic['PRACTICE'] = 'Farmland'\n",
    "\n",
    "farmland_mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6321a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preliminary model training framework\n",
    "\n",
    "#Construct from for loops:\n",
    "ulti_log = pd.concat([contour_mosaic, dam_mosaic, grassed_mosaic, \\\n",
    "                      terrace_mosaic, basin_mosaic, strip_mosaic, farmland_mosaic]).reset_index()\n",
    "\n",
    "## Load from csv:\n",
    "# ulti_log = pd.read_csv('~F:/Iowa BMP/mosaic_bands.csv')\n",
    "\n",
    "# ulti_log.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d35e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>HUC_12</th>\n",
       "      <th>NRCS_CODE</th>\n",
       "      <th>PRACTICE</th>\n",
       "      <th>Present2_1</th>\n",
       "      <th>CREATOR_NA</th>\n",
       "      <th>Present80s</th>\n",
       "      <th>SHAPE_Area</th>\n",
       "      <th>LAST_EDIT_</th>\n",
       "      <th>Merge</th>\n",
       "      <th>...</th>\n",
       "      <th>R</th>\n",
       "      <th>B</th>\n",
       "      <th>imagedate</th>\n",
       "      <th>G</th>\n",
       "      <th>N</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>ORIG_FID</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>BUFF_DIST</th>\n",
       "      <th>CID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>070802011202</td>\n",
       "      <td>332</td>\n",
       "      <td>Contour Buffer Strips</td>\n",
       "      <td>1</td>\n",
       "      <td>MP</td>\n",
       "      <td>0</td>\n",
       "      <td>186501.155605</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "      <td>20100829</td>\n",
       "      <td>86</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>070802011202</td>\n",
       "      <td>332</td>\n",
       "      <td>Contour Buffer Strips</td>\n",
       "      <td>1</td>\n",
       "      <td>MP</td>\n",
       "      <td>0</td>\n",
       "      <td>186501.155605</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>98</td>\n",
       "      <td>20100829</td>\n",
       "      <td>76</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>070802011202</td>\n",
       "      <td>332</td>\n",
       "      <td>Contour Buffer Strips</td>\n",
       "      <td>1</td>\n",
       "      <td>MP</td>\n",
       "      <td>0</td>\n",
       "      <td>186501.155605</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>98</td>\n",
       "      <td>20100829</td>\n",
       "      <td>76</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>070802011202</td>\n",
       "      <td>332</td>\n",
       "      <td>Contour Buffer Strips</td>\n",
       "      <td>1</td>\n",
       "      <td>MP</td>\n",
       "      <td>0</td>\n",
       "      <td>186501.155605</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>92</td>\n",
       "      <td>20100829</td>\n",
       "      <td>81</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>070802011202</td>\n",
       "      <td>332</td>\n",
       "      <td>Contour Buffer Strips</td>\n",
       "      <td>1</td>\n",
       "      <td>MP</td>\n",
       "      <td>0</td>\n",
       "      <td>186501.155605</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>99</td>\n",
       "      <td>20100829</td>\n",
       "      <td>88</td>\n",
       "      <td>148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431288</th>\n",
       "      <td>4995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Farmland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>108</td>\n",
       "      <td>20100813</td>\n",
       "      <td>112</td>\n",
       "      <td>134</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431289</th>\n",
       "      <td>4996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Farmland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>108</td>\n",
       "      <td>20100813</td>\n",
       "      <td>112</td>\n",
       "      <td>134</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431290</th>\n",
       "      <td>4997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Farmland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>112</td>\n",
       "      <td>20100813</td>\n",
       "      <td>123</td>\n",
       "      <td>149</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431291</th>\n",
       "      <td>4998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Farmland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>109</td>\n",
       "      <td>20100813</td>\n",
       "      <td>112</td>\n",
       "      <td>130</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431292</th>\n",
       "      <td>4999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Farmland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>113</td>\n",
       "      <td>20100813</td>\n",
       "      <td>121</td>\n",
       "      <td>141</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>431293 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        HUC_12 NRCS_CODE               PRACTICE Present2_1  \\\n",
       "0           0  070802011202       332  Contour Buffer Strips          1   \n",
       "1           1  070802011202       332  Contour Buffer Strips          1   \n",
       "2           2  070802011202       332  Contour Buffer Strips          1   \n",
       "3           3  070802011202       332  Contour Buffer Strips          1   \n",
       "4           4  070802011202       332  Contour Buffer Strips          1   \n",
       "...       ...           ...       ...                    ...        ...   \n",
       "431288   4995           NaN       NaN               Farmland        NaN   \n",
       "431289   4996           NaN       NaN               Farmland        NaN   \n",
       "431290   4997           NaN       NaN               Farmland        NaN   \n",
       "431291   4998           NaN       NaN               Farmland        NaN   \n",
       "431292   4999           NaN       NaN               Farmland        NaN   \n",
       "\n",
       "       CREATOR_NA Present80s     SHAPE_Area LAST_EDIT_ Merge  ...   R    B  \\\n",
       "0              MP          0  186501.155605                   ...  74  100   \n",
       "1              MP          0  186501.155605                   ...  65   98   \n",
       "2              MP          0  186501.155605                   ...  65   98   \n",
       "3              MP          0  186501.155605                   ...  71   92   \n",
       "4              MP          0  186501.155605                   ...  74   99   \n",
       "...           ...        ...            ...        ...   ...  ...  ..  ...   \n",
       "431288        NaN        NaN            NaN        NaN   NaN  ...  84  108   \n",
       "431289        NaN        NaN            NaN        NaN   NaN  ...  84  108   \n",
       "431290        NaN        NaN            NaN        NaN   NaN  ...  99  112   \n",
       "431291        NaN        NaN            NaN        NaN   NaN  ...  91  109   \n",
       "431292        NaN        NaN            NaN        NaN   NaN  ...  95  113   \n",
       "\n",
       "        imagedate    G    N  Shape_Leng  ORIG_FID  Shape_Area  BUFF_DIST  CID  \n",
       "0        20100829   86  160         NaN       NaN         NaN        NaN  NaN  \n",
       "1        20100829   76  127         NaN       NaN         NaN        NaN  NaN  \n",
       "2        20100829   76  127         NaN       NaN         NaN        NaN  NaN  \n",
       "3        20100829   81  135         NaN       NaN         NaN        NaN  NaN  \n",
       "4        20100829   88  148         NaN       NaN         NaN        NaN  NaN  \n",
       "...           ...  ...  ...         ...       ...         ...        ...  ...  \n",
       "431288   20100813  112  134    0.066038     100.0    0.000337     1000.0  0.0  \n",
       "431289   20100813  112  134    0.066038     100.0    0.000337     1000.0  0.0  \n",
       "431290   20100813  123  149    0.066038     100.0    0.000337     1000.0  0.0  \n",
       "431291   20100813  112  130    0.066038     100.0    0.000337     1000.0  0.0  \n",
       "431292   20100813  121  141    0.066038     100.0    0.000337     1000.0  0.0  \n",
       "\n",
       "[431293 rows x 26 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulti_log\n",
    "\n",
    "# for col in ulti_log.columns:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f3a05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add NDVI and NDWI - until you can get addbands functions to work with extraction\n",
    "ulti_log['ndvi'] = (ulti_log['N']-ulti_log['R'])/(ulti_log['N']+ulti_log['R'])\n",
    "ulti_log['ndwi'] = (ulti_log['G']-ulti_log['N'])/(ulti_log['G']+ulti_log['N']) #not making use of SWIR\n",
    "\n",
    "#add other indices?\n",
    "\n",
    "# Get the labeled training data for each band\n",
    "red_train = ulti_log['R']\n",
    "blue_train = ulti_log['B'] ##WHY DOES THIS WORK FOR MOSAIC BUT NOT FOR NON MOSAIC\n",
    "green_train = ulti_log['G']\n",
    "nir_train = ulti_log['N']\n",
    "ndvi_train = ulti_log['ndvi']\n",
    "ndwi_train = ulti_log['ndwi']\n",
    "\n",
    "xargs = np.column_stack((red_train, nir_train, green_train, blue_train, ndvi_train, ndwi_train)) \n",
    "# # put the three features as three columns of the matrix\n",
    "\n",
    "# # Get the labeled value\n",
    "yargs = ulti_log['PRACTICE']\n",
    "\n",
    "seed = 3\n",
    "\n",
    "# Split to training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "xargs_train, xargs_test, yargs_train, yargs_test = train_test_split(xargs, yargs, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "260b1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "'''\n",
    "##LOOK INTO THIS: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.\n",
    "model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n",
    "'''\n",
    "\n",
    "#Random forest classification\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('forest', RandomForestClassifier(n_estimators = 100, min_samples_leaf=10, random_state=seed))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(xargs_train, yargs_train) #Train\n",
    "y_pred=pipe.predict(xargs_test) #Fit the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e4e34fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6671419793876581\n",
      "[[  700  1821   348     4     1    76    18]\n",
      " [  106 47049  1681    31    60   262   111]\n",
      " [   54  7969  7109    15    21   374   102]\n",
      " [   16  2459   414   149     7    93    35]\n",
      " [    1   491    47     2   247    19     8]\n",
      " [   52  5974  1352    21    22  1665   140]\n",
      " [   35  3277   887    19    19   268   628]]\n"
     ]
    }
   ],
   "source": [
    "#Model results\n",
    "print(accuracy_score(yargs_test, y_pred))\n",
    "print(confusion_matrix(yargs_test, y_pred))\n",
    "#https://stackoverflow.com/questions/62672842/how-to-improve-f1-score-for-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ee32ae50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  964, 69040, 11838,   241,   377,  2757,  1042], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(confusion_matrix(yargs_test, y_pred)) #why are these numbers so #172231 total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "44a5af28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400576            Farmland\n",
       "313007            Farmland\n",
       "229198            Farmland\n",
       "430580            Farmland\n",
       "199506            Farmland\n",
       "                ...       \n",
       "113939             Terrace\n",
       "102984    Grassed Waterway\n",
       "142237             Terrace\n",
       "383540            Farmland\n",
       "184386       Stripcropping\n",
       "Name: PRACTICE, Length: 86259, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yargs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b352381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRACTICE\n",
       "Contour Buffer Strips                         15000\n",
       "Farmland                                     245000\n",
       "Grassed Waterway                              79548\n",
       "Pond Dam                                      15725\n",
       "Stripcropping                                  4000\n",
       "Terrace                                       46047\n",
       "Water and Sediment Control Basin (WASCOB)     25973\n",
       "Name: imagedate, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ulti_log.groupby('PRACTICE')['imagedate'].count() #'index' not present in farmland extraction\n",
    "\n",
    "df #i have concerns stripcropping is not getting data from enough locations - also pond dam seems low? see gis file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244852e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export df to csv, to save time\n",
    "\n",
    "import os\n",
    "\n",
    "out_dir = os.path.expanduser('~F:/Iowa BMP/')\n",
    "out_csv = os.path.join(out_dir, 'mosaic_bands.csv')\n",
    "# ulti_log.to_csv(out_csv, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c177d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning\n",
    "\n",
    "#This takes way tooo long\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'forest__n_estimators': [100, 200, 300],\n",
    "#     'forest__min_samples_leaf': [5, 10, 20],\n",
    "#     'forest__max_depth': [None, 10, 20]\n",
    "# }\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "# grid_search.fit(xargs_train, yargs_train)\n",
    "\n",
    "# # Get the best parameters and the best estimator\n",
    "# best_params = grid_search.best_params_\n",
    "# best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# # Predict on the test set using the best estimator\n",
    "# y_pred = best_estimator.predict(xargs_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(yargs_test, y_pred))\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(yargs_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a90eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6623836591554366\n",
      "[[11909   635  3884    57   338  1221   192]\n",
      " [  741  8168  4115    49   138  1533   293]\n",
      " [ 2771  2469 71354   285   669  7243   745]\n",
      " [  128   124  1318   567    36   529    48]\n",
      " [  404   125  1271    21  4226   366    55]\n",
      " [ 1883  1865 16005   234   434 15635   555]\n",
      " [  456   456  3209    43    99  1106  2224]]\n"
     ]
    }
   ],
   "source": [
    "from geemap import ml\n",
    "from sklearn import ensemble\n",
    "\n",
    "# create a classifier and fit\n",
    "n_trees = 10\n",
    "rf = ensemble.RandomForestClassifier(n_trees).fit(xargs_train, yargs_train) #needs scaling, more hyperparameters\n",
    "\n",
    "y_pred=rf.predict(xargs_test) \n",
    "print(accuracy_score(yargs_test, y_pred))\n",
    "print(confusion_matrix(yargs_test, y_pred)) \n",
    "\n",
    "feature_names = [\"N\", \"R\", \"G\", \"B\", \"ndvi\", \"ndwi\"]\n",
    "\n",
    "trees = ml.rf_to_strings(rf, feature_names)\n",
    "\n",
    "# create a ee classifier to use with ee objects from the trees\n",
    "# ee_classifier = ml.strings_to_classifier(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trees[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a3c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trees) == n_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ee classifier to use with ee objects from the trees\n",
    "ee_classifier = ml.strings_to_classifier(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d49401d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1/projects/earthengine-legacy/thumbnails/5601d286af31b12076f7c9cd1d41b3b1-9c03e25b1adf6dbbdb8b6c375e624bed:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to F:\\Iowa BMP\\Geotiffs\\aoi_addedbands.tif\n"
     ]
    }
   ],
   "source": [
    "#Export image test\n",
    "\n",
    "aoi = geemap.shp_to_ee('F:/Iowa BMP/Iowa clipped shapefiles/aoi/aoi3.shp').geometry() #use aoi5 for addedbands, aoi3 else\n",
    "image = iowa_mosaic_2010\n",
    "\n",
    "out_dir = os.path.expanduser('~F:/Iowa BMP/Geotiffs/')\n",
    "out_tif = os.path.join(out_dir, 'aoi.tif')\n",
    "\n",
    "image = image.clip(aoi).unmask()\n",
    "\n",
    "# geemap.ee_export_image(\n",
    "#     image, filename=out_tif, scale=1, region=aoi, file_per_band=False\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "499059d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count for G : 16063\n"
     ]
    }
   ],
   "source": [
    "#Count of each pixel type, to inform sample sizes for machine learning model\n",
    "\n",
    "# Specify the band of interest\n",
    "band_name = 'G'  \n",
    "\n",
    "# Reduce region to get the count for the specified band\n",
    "count_band = iowa_mosaic_2010.reduceRegion(\n",
    "    reducer=ee.Reducer.count(), \n",
    "    geometry=dam_clip,\n",
    "    scale=1\n",
    ")\n",
    "\n",
    "# Get the count for the specified band\n",
    "band_count = count_band.get(band_name)\n",
    "\n",
    "# Print the count\n",
    "print('Count for', band_name, ':', band_count.getInfo())\n",
    "\n",
    "# iowa_mosaic_2010.reduceRegion(reducer = ee.Reducer.count(), geometry = buffer_points, scale = 30)\n",
    "\n",
    "##At 1 m resolution (error due to maxpixels)\n",
    "#Total: 2119153633\n",
    "#Strip_clip: 11260669\n",
    "#Terrace_clip:  363031\n",
    "#Contour_clip: 22089427\n",
    "#Basin_clip: 38645\n",
    "#Dam_clip: 14334\n",
    "#Grassed: 16920537\n",
    "#Farmland: 2068466990\n",
    "\n",
    "\n",
    "##At 30m resolution (to check percentages):\n",
    "#Total: 468175\n",
    "#Strip_clip: 2499\n",
    "#Terrace_clip: 14071  \n",
    "#Contour_clip: 4909\n",
    "#Basin_clip: 1773\n",
    "#Dam_clip: 688\n",
    "#Grassed: 3821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "355c3543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "farm count = 2068466990\n",
      "farm percent = 97.60816572188563\n",
      "strip percent = 0.5313757730749671\n",
      "terrace percent = 0.017130942955092487\n",
      "contour percent = 1.042370248953064\n",
      "basin percent = 0.0018236053959566792\n",
      "dam percent = 0.0006764021152967535\n",
      "grassed percent = 0.7984573056199932\n",
      "Multiply by 5000 rather than 100 to get feature.limit() for each extraction function\n",
      "line polygon (terrace, basin, dam) sample size percents of whole go way up when scale is increased to 30m\n"
     ]
    }
   ],
   "source": [
    "print('farm count = ' + str(2119153633 - (11260669+363031+22089427+38645+14334+16920537)))\n",
    "print('farm percent = ' + str(2068466990/2119153633*100))\n",
    "print('strip percent = ' + str(11260669/2119153633*100))\n",
    "print('terrace percent = ' + str(363031/2119153633*100))\n",
    "print('contour percent = ' + str(22089427/2119153633*100))\n",
    "print('basin percent = ' + str(38645/2119153633*100))\n",
    "print('dam percent = ' + str(14334/2119153633*100))\n",
    "print('grassed percent = ' + str(16920537/2119153633*100))\n",
    "\n",
    "print('Multiply by 5000 rather than 100 to get feature.limit() for each extraction function')\n",
    "\n",
    "# print('30m farm count = ' + str(468175 - (2499+14071+4909+1773+688+3821)))\n",
    "# print('30m farm percent = ' + str(440414/468175*100))\n",
    "# print('30m strip percent = ' + str(2499/468175*100))\n",
    "# print('30m terrace percent = ' + str(14071/468175*100))\n",
    "# print('30m contour percent = ' + str(4909/468175*100))\n",
    "# print('30m basin percent = ' + str(1773/468175*100))\n",
    "# print('30m dam percent = ' + str(688/468175*100))\n",
    "# print('30m grassed percent = ' + str(3821/468175*100))\n",
    "\n",
    "print('line polygon (terrace, basin, dam) sample size percents of whole go way up when scale is increased to 30m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "376206c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You's a fish a feesh\n"
     ]
    }
   ],
   "source": [
    "# Define a function to convert a string to \"U'z a feesh\"\n",
    "def convert_to_feesh(s):\n",
    "    # Define a dictionary to map characters to their feesh equivalents\n",
    "    feesh_dict = {\n",
    "        'U': 'U\\'',\n",
    "        'u': 'u',\n",
    "        'a': 'a',\n",
    "        'f': 'f',\n",
    "        'e': 'e',\n",
    "        's': 's',\n",
    "        'h': 'h'\n",
    "    }\n",
    "    \n",
    "    # Convert characters to feesh equivalents\n",
    "    feesh_string = ''.join(feesh_dict.get(char, char) for char in s)\n",
    "    \n",
    "    # Add \" a feesh\" to the end\n",
    "    feesh_string += \" a feesh\"\n",
    "    \n",
    "    return feesh_string\n",
    "\n",
    "# Define the input string\n",
    "input_string = \"You's a fish\"\n",
    "\n",
    "# Convert the input string to \"U'z a feesh\" and print it\n",
    "print(convert_to_feesh(input_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978282d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gee] *",
   "language": "python",
   "name": "conda-env-gee-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
