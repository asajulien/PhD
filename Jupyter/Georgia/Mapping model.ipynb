{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8018256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "from IPython.display import display\n",
    "import ee\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "from IPython.display import display\n",
    "import os\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as sm\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from math import sqrt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9be637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 276.55574133183586\n",
      "Mean Squared Error: 163296.2224849244\n",
      "Root Mean Squared Error: 404.0992730566641\n",
      "The r squared is: 0.5601754521681688\n",
      "testing r2 is: 0.5601754521681688\n",
      "training r2 is: 0.8998169469260654\n",
      "NRMSE is: 0.11215683251900761\n",
      "MEAN BASELINE:\n",
      "Mean Absolute Error: 435.32804771950657\n",
      "Root Mean Squared Error: 611.3683266898607\n"
     ]
    }
   ],
   "source": [
    "##Model\n",
    "##PC:\n",
    "path = r'C:/Users/arj26323/Documents/Data/Biomass datasets/Sapelo/Yearly data/Flats' \n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "##Bands and indices\n",
    "\n",
    "df['Sensor'] = np.where(df['Year']<2013, 'Landsat 5', 'Landsat 8') ##make sure no other sensors are being used\n",
    "\n",
    "df['ndvi'] = np.where(df['Sensor'] == 'Landsat 5', (df['B4']-df['B3'])/(df['B4']+df['B3']), \\\n",
    "                      (df['B5']-df['B4'])/(df['B5']+df['B4'])) ##ndvi conditional based on whether sensor is Landsat-5 or 8\n",
    "\n",
    "df['Blue_band'] = np.where(df['Sensor'] == 'Landsat 5', df['B1'], df['B2'])\n",
    "df['Green_band'] = np.where(df['Sensor'] == 'Landsat 5', df['B2'], df['B3'])\n",
    "df['Red_band'] = np.where(df['Sensor'] == 'Landsat 5', df['B3'], df['B4'])\n",
    "df['NIR_band'] = np.where(df['Sensor'] == 'Landsat 5', df['B4'], df['B5'])\n",
    "df['SWIR1_band'] = np.where(df['Sensor'] == 'Landsat 5', df['B5'], df['B6'])\n",
    "df['SWIR2_band'] = np.where(df['Sensor'] == 'Landsat 5', df['B7'], df['B7'])\n",
    "\n",
    "df['savi'] = ((df['NIR_band']-df['Red_band'])*1.5)/(df['NIR_band']+df['Red_band']+0.5)\n",
    "df['wdrvi5'] = (0.5*df['NIR_band']-df['Red_band'])/(0.5*df['NIR_band']+df['Red_band'])\n",
    "df['nd_r_g'] = (df['Red_band']-df['Green_band'])/(df['Red_band']+df['Green_band'])\n",
    "df['nd_g_b'] = (df['Green_band']-df['Blue_band'])/(df['Green_band']+df['Blue_band'])\n",
    "df['nd_swir2_nir'] = (df['SWIR2_band']-df['NIR_band'])/(df['SWIR2_band']+df['NIR_band'])\n",
    "df['nd_swir2_r'] = (df['SWIR2_band']-df['Red_band'])/(df['SWIR2_band']+df['Red_band'])\n",
    "\n",
    "##DAYMET data added - yearly averages\n",
    "##PC:\n",
    "path2 = r'C:/Users/arj26323/Documents/Data/Biomass datasets/Daymet/GA/Yearly averages' \n",
    "all_files2 = glob.glob(path2 + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files2:\n",
    "    dm = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(dm)\n",
    "\n",
    "dm = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "dm['ident'] = dm['Latitude']/dm['Longitude']\n",
    "\n",
    "##Seasonal averages: growing season (defined as between 3/1 and 10/31)\n",
    "path3 = r'C:/Users/arj26323/Documents/Data/Biomass datasets/Daymet/GA/Growing season' \n",
    "all_files3 = glob.glob(path2 + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files3:\n",
    "    dm2 = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(dm2)\n",
    "\n",
    "dm2 = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "dm2['ident'] = dm2['Latitude']/dm2['Longitude']\n",
    "\n",
    "dm2 = dm2.rename(columns={'dayl': 'sn_dayl', 'prcp': 'sn_prcp', 'srad': 'sn_srad', \\\n",
    "                        'tmax': 'sn_tmax','tmin': 'sn_tmin','vp': 'sn_vp'})\n",
    "\n",
    "##Merging elevation point data with band dataset prior to model development\n",
    "\n",
    "elev_10m = pd.read_csv('C:/Users/arj26323/Documents/Data/Biomass datasets/Sapelo/Point_elevation/DEM_vals_10m.csv')\n",
    "\n",
    "elev_10m.rename(columns={'first':'Elevation'}, inplace=True)\n",
    "\n",
    "## drop rows which have same lat and long and keep latest entry\n",
    "dfx = elev_10m.drop_duplicates(\n",
    "  subset = ['Latitude', 'Longitude'],\n",
    "  keep = 'last').reset_index(drop = True)\n",
    "\n",
    "dfx = dfx[['Elevation', 'Latitude', 'Longitude']]\n",
    "dfx['ident'] = dfx['Latitude']/dfx['Longitude']\n",
    "\n",
    "df['ident'] = df['Latitude']/df['Longitude'] \n",
    "\n",
    "df0 = pd.merge(df, dfx, on = 'ident')\n",
    "df0_sn = pd.merge(df0, dm2)\n",
    "df1 = pd.merge(df0_sn, dm)\n",
    "\n",
    "df1 = df1[df1['ndvi'].notna()] ##remove rows with NaN for columns used in the model \n",
    "df1 = df1[df1['prcp'].notna()] ##CAREFUL; added 7/11/22\n",
    "df1 = df1[df1['Species_Code'] == 'A1'] ##careful here\n",
    "df1 = df1[(df1['flats'] < 0.1) & (df1['flats'] > -0.1)] ##Increases NRMSE by 0.003, but seems to be a better fit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xargs=df1[['ndvi', 'nd_swir2_r', 'nd_swir2_nir', 'nd_g_b', 'nd_r_g', 'wdrvi5', 'savi', 'Elevation', \\\n",
    "           'prcp', 'dayl', 'tmax', 'tmin', 'srad', 'vp']]\n",
    "\n",
    "yargs=df1['Plant_Biomass'] \n",
    "\n",
    "size_x = 0.2\n",
    "seed = 0\n",
    "xargs_train, xargs_test, yargs_train, yargs_test = train_test_split(xargs, yargs, test_size=size_x, random_state = seed) \n",
    "## 80% training and 20% test\n",
    "# # Pipeline example:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('forest', RandomForestRegressor(n_estimators=100, random_state=seed))])\n",
    "pipe.fit(xargs_train, yargs_train)\n",
    "y_pred=pipe.predict(xargs_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(yargs_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(yargs_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(yargs_test, y_pred)))\n",
    "r_square = metrics.r2_score(yargs_test, y_pred)\n",
    "print(\"The r squared is: \" + str(r_square))\n",
    "print('testing r2 is: ' + str(pipe.score(xargs_test, yargs_test)))\n",
    "print('training r2 is: ' + str(pipe.score(xargs_train, yargs_train)))\n",
    "print('NRMSE is: ' + str(np.sqrt(metrics.mean_squared_error(yargs_test, y_pred))/np.ptp(yargs_test)))\n",
    "\n",
    "# Mean\n",
    "print('MEAN BASELINE:')\n",
    "y_pred_mean = [np.mean(yargs_train)] * len(yargs_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(yargs_test, y_pred_mean))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(yargs_test, y_pred_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca57f967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977e197c6f124e4bb9c9b1d09e83ba3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40, -100], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Tâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##GEE\n",
    "ee.Initialize()\n",
    "\n",
    "#Landsat\n",
    "ga19 = ee.Image('LANDSAT/LC08/C01/T1_SR/LC08_017038_20190927')\n",
    "\n",
    "def maskL5sr(image):\n",
    "  ## Bits 3 and 5 are cloud shadow and cloud, respectively.\n",
    "  cloudShadowBitMask = 1 << 3\n",
    "  cloudsBitMask = 1 << 5\n",
    "\n",
    "  ##Get the pixel QA band.\n",
    "  qa = image.select('pixel_qa')\n",
    "\n",
    "  ##Both flags should be set to zero, indicating clear conditions.\n",
    "  mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0) \\\n",
    "      .And(qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
    "\n",
    "  ##Return the masked image, scaled to reflectance, without the QA bands.\n",
    "  return image.updateMask(mask).divide(10000) \\\n",
    "      .select(\"B[0-9]*\") \\\n",
    "      .copyProperties(image, [\"system:time_start\"])\n",
    "\n",
    "##Water masking\n",
    "\n",
    "##Load or import the Hansen et al. forest change dataset.\n",
    "hansenImage = ee.Image('UMD/hansen/global_forest_change_2015')\n",
    "\n",
    "##Select the land/water mask.\n",
    "datamask = hansenImage.select('datamask')\n",
    "\n",
    "##Create a binary mask.\n",
    "watermask = datamask.eq(1)\n",
    "\n",
    "gamasked19 = ee.Image(maskL5sr(ga19)).updateMask(watermask)\n",
    "\n",
    "def addFLATS(image):\n",
    "    flats = ee.Image(0).expression(\n",
    "        '1-1/(1-2.718281828459045**(-1.57 + 19.97*(RED-NIR)/(RED+NIR) + 68.55*(GREEN-RED)/(GREEN+RED)))', {\n",
    "            'NIR': image.select('B5'),\n",
    "            'RED': image.select('B4'),\n",
    "            'GREEN': image.select('B3')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(flats.rename('flats'))\n",
    "\n",
    "FLAT19 = addFLATS(gamasked19)\n",
    "\n",
    "#Daymet\n",
    "daymet = ee.ImageCollection('NASA/ORNL/DAYMET_V4') \\\n",
    "     .filter(ee.Filter.date('2019-01-01', '2019-12-31')) \\\n",
    "     .mean()\n",
    "\n",
    "dm_precip = daymet.select('prcp')\n",
    "dm_maxtemp = daymet.select('tmax')\n",
    "dm_mintemp = daymet.select('tmin')\n",
    "dm_daylight = daymet.select('dayl')\n",
    "dm_srad = daymet.select('srad')\n",
    "dm_snow = daymet.select('swe')\n",
    "dm_vapor = daymet.select('vp')\n",
    "\n",
    "prcpVis = {\n",
    "  'min': -40.0,\n",
    "  'max': 30.0,\n",
    "  'palette': ['1621A2', 'white', 'cyan', 'green', 'yellow', 'orange', 'red'],\n",
    "}\n",
    "\n",
    "daylVis = {\n",
    "  'min': 0,\n",
    "  'max': 50000.0,\n",
    "  'palette': ['1621A2', 'white', 'cyan', 'green', 'yellow', 'orange', 'red'],\n",
    "}\n",
    "\n",
    "sradVis = {\n",
    "  'min': 0,\n",
    "  'max': 400.0,\n",
    "  'palette': ['1621A2', 'white', 'cyan', 'green', 'yellow', 'orange', 'red'],\n",
    "}\n",
    "\n",
    "vpVis = {\n",
    "  'min': 0,\n",
    "  'max': 1500,\n",
    "  'palette': ['1621A2', 'white', 'cyan', 'green', 'yellow', 'orange', 'red'],\n",
    "}\n",
    "\n",
    "#DEM\n",
    "dem2 = ee.Image('USGS/3DEP/10m')\n",
    "\n",
    "dem_params = {\n",
    "    'min': 0,\n",
    "    'max': 4000,\n",
    "    'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5'],\n",
    "}\n",
    "\n",
    "\n",
    "Map = geemap.Map(center=[40,-100], zoom=4)\n",
    "\n",
    "Map.addLayer(FLAT19, {'bands': ['B5',  'B4',  'B3'], 'min': 0, 'max': 0.2}, 'Flats 2019')\n",
    "Map.addLayer(dem2, dem_params, '10m DEM', True, 1)\n",
    "Map.addLayer(dm_precip, prcpVis, \"Precipitation\")\n",
    "Map.addLayer(dm_maxtemp, prcpVis, \"Maxtemp\")\n",
    "Map.addLayer(dm_mintemp, prcpVis, \"Mintemp\")\n",
    "Map.addLayer(dm_daylight, daylVis, \"Daylight\")\n",
    "Map.addLayer(dm_srad, sradVis, \"SRAD\")\n",
    "Map.addLayer(dm_snow, prcpVis, \"Snowpack water?\")\n",
    "Map.addLayer(dm_vapor, vpVis, \"Vaporpressure\")\n",
    "\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make all variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
