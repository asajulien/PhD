{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##VA biomass analysis: GEE/ndvi regressions\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pdb\n",
    "# from IPython.display import display\n",
    "# import os\n",
    "# import seaborn as sns\n",
    "# import statsmodels.formula.api as sm\n",
    "# from numpy.polynomial.polynomial import polyfit\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import sklearn\n",
    "# from math import sqrt\n",
    "\n",
    "##data analysis with cloud-masked data\n",
    "#masked_ndvi = pd.read_csv('/Users/asariversjulien/Documents/Data/CSV files/masked_ndvi.csv')\n",
    "# l5l7l8 = pd.read_csv('/Users/asariversjulien/Documents/Data/CSV files/L5L7L8_combined.csv')\n",
    "# masked_ndvi = pd.merge(newdf, l5l7l8, on=['year', 'siteName'])   \n",
    "    \n",
    "# masked_ndvi['EOYBYear'] = pd.to_datetime(masked_ndvi['EOYBYear'], format = '%Y')\n",
    "# masked_ndvi['imagedate'] = pd.to_datetime(masked_ndvi['imagedate'], format = '%m/%d/%y')\n",
    "# masked_ndvi['year'] = pd.DatetimeIndex(pd.to_datetime(round(masked_ndvi['year']), format = '%Y')).year\n",
    "\n",
    "# masked_ndvi['sqrtLive'] = np.sqrt(masked_ndvi['liveMass']) ##in case 'liveMass' does not meet assumptions\n",
    "# xxyrs = [2001, 2003, 2004, 2005, 2006, 2007, 2012, 2013, 2014, 2015, 2016]\n",
    "# masked_ndvi = masked_ndvi[masked_ndvi['year'].isin(xxyrs)] ##filtering out years where high tide -> flooded pixels\n",
    "\n",
    "# masked_ndvi = masked_ndvi[masked_ndvi['ndvi'] > 0] ##Gets rid of obviously flooded pixels and NA values\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  ## more options can be specified also\n",
    "#     print(masked_ndvi)\n",
    "\n",
    "\n",
    "\n",
    "##Training and testing biomass ~ ndvi: getting datasets\n",
    "#train, test = train_test_split(masked_ndvi, test_size = 0.2) ##have to redo next chunk every time you run this\n",
    "\n",
    "\n",
    "\n",
    "##Training and testing biomass ~ ndvi\n",
    "# result = sm.ols(formula=\"liveMass ~ VDVI\", data = train).fit() #mass = 1809.7 * vdvi + 311.5\n",
    "# print(result.params)\n",
    "# print(result.summary())\n",
    "\n",
    "# g = sns.lmplot(x = \"VDVI\", y = \"liveMass\", ci = 95, data=train) ##CI seems a little too small?\n",
    "# g.set_axis_labels(\"VDVI\", \"Average biomass (g/$m^2$)\")\n",
    "# g.set(ylim=(0, None))\n",
    "\n",
    "\n",
    "\n",
    "##plot observed vs predicted\n",
    "# test['predicted'] = 1809.7 * test['VDVI'] + 311.5\n",
    "# x = sns.lmplot(x = \"liveMass\", y = \"predicted\", fit_reg=False, data=test)\n",
    "# x.set_axis_labels(\"Predicted biomass (g/$m^2$)\", \"Observed biomass (g/$m^2$)\")\n",
    "# x.set(ylim=(0, None))\n",
    "\n",
    "# plt.plot([100, 700], [100, 700], '--')\n",
    "\n",
    "# ##RMSE\n",
    "# actual = test['liveMass']\n",
    "# predicted = test['predicted']\n",
    "\n",
    "# mse = sklearn.metrics.mean_squared_error(actual, predicted)\n",
    "# sqrt(mse)\n",
    "\n",
    "\n",
    "##Plots - all data together (no train/test)\n",
    "# g = sns.lmplot(x = \"VDVI\", y = \"liveMass\", ci = 95, data=masked_ndvi) ##CI seems a little too small?\n",
    "# g.set_axis_labels(\"NDVI value\", \"Average biomass (g/$m^2$)\")\n",
    "# g.set(ylim=(0, None))\n",
    "\n",
    "# masked_ndvi['VDVI'].corr(masked_ndvi['liveMass'], method = 'pearson')\n",
    "\n",
    "# #my_path = os.path.abspath('/Users/asariversjulien/Documents/Georgia/Project')\n",
    "# #my_file = 'p1.png'\n",
    "# #g.savefig(os.path.join(my_path, my_file), bbox_inches = 'tight')\n",
    "\n",
    "# ##FLOODED PLOTS. something to consider with image collection that you have\n",
    "# ##Error bars???\n",
    "\n",
    "\n",
    "\n",
    "# result = sm.ols(formula=\"liveMass ~ VDVI\", data = masked_ndvi).fit()\n",
    "# print(result.params)\n",
    "# print(result.summary())\n",
    "\n",
    "\n",
    "\n",
    "# site_list = ['Box_Tree', 'Gator', 'Oyster']\n",
    "# df2 = mn_siteyears[mn_siteyears['siteName'].isin(site_list)]\n",
    "# g = sns.FacetGrid(df2, col=\"siteName\", col_wrap=4,  sharex=False)\n",
    "# #g = sns.FacetGrid(masked_ndvi[masked_ndvi['siteName'] == 'Box_Tree'], col=\"siteName\",  sharex=False)\n",
    "# g = g.map(plt.scatter, 'EOYBYear', 'liveMass') ##interesting patterns here!!\n",
    "# g.set_axis_labels(\"Year\", \"Biomass (g/$m^2$)\")\n",
    "# ##Boxtree/Cushmans/Hog/Oyster = steady decrease in biomass over time\n",
    "# ##Gator cyclical. Steelmans the only site that increased, but low N\n",
    "\n",
    "\n",
    "\n",
    "# x_x = sns.FacetGrid(df2, col=\"siteName\", col_wrap=4,  sharex=False)\n",
    "# g_x = x_x.map(plt.scatter, 'year', 'ndvi')\n",
    "\n",
    "\n",
    "\n",
    "# y_y = sns.FacetGrid(df2, col=\"siteName\",  sharex=False) ##the way I'm doing things, ndvi bad predictor!!\n",
    "# g_y = y_y.map(plt.scatter, 'ndvi', 'liveMass')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
