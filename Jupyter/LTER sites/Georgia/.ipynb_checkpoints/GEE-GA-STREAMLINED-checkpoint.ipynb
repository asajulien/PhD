{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "643f2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "from IPython.display import display\n",
    "import ee\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de43d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ee.Authenticate()\n",
    "#geemap.update_package()\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "Map = geemap.Map(center=[31.539096,-81.422318], zoom=10)\n",
    "\n",
    "##Adding every plot coordinate\n",
    "allplots_fc = 'C:/Users/arj26323/Documents/Data/Biomass datasets/Sapelo/GA_allplots_NEW.csv'\n",
    "fc_all = geemap.csv_to_ee(allplots_fc, latitude = \"Latitude\", longitude = \"Longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190611be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to cloud mask from the pixel_qa band of Landsat 5/8 SR data.\n",
    "\n",
    "#IS THIS SAME BETWEEN SENSORS: https://github.com/giswqs/geemap/discussions/672\n",
    "\n",
    "def maskL8sr(image):\n",
    "    qaMask = image.select('QA_PIXEL').bitwiseAnd(int('11111', 2)).eq(0)\n",
    "    saturationMask = image.select('QA_RADSAT').eq(0)\n",
    "    # Apply the scaling factors to the appropriate bands.\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
    "    # Replace the original bands with the scaled ones and apply the masks.\n",
    "    return image.addBands(opticalBands, None, True) \\\n",
    "    .addBands(thermalBands, None, True) \\\n",
    "    .updateMask(qaMask) \\\n",
    "    .updateMask(saturationMask)\n",
    "\n",
    "#NOTE 10/6/2022 - This has been updated for Landsat Collection 2 https://www.usgs.gov/landsat-missions/landsat-collection-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0de695b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TIDAL FILTERING; from Narron et al. 2022\n",
    "##Utilizes L8 bands 4 and 6 for NDWI, and bands 3 and 4 (for pheno)\n",
    "##Does it work for Landsat 5?\n",
    "\n",
    "# def addFLATS(image):\n",
    "#     flats = ee.Image(0).expression(\n",
    "#         '1/(1+2.718281828459045**-(-1.57 + 20*(RED-SWIR)/(RED+SWIR) + 68.6*(GREEN-RED)/(GREEN+RED)))', {\n",
    "#             'SWIR': image.select('SR_B6'),\n",
    "#             'RED': image.select('SR_B4'),\n",
    "#             'GREEN': image.select('SR_B3')\n",
    "#         })\n",
    "    \n",
    "#     return image.addBands(flats.rename('flats'))\n",
    "\n",
    "# def addFLATSL5(image):\n",
    "#     flats = ee.Image(0).expression(\n",
    "#         '1/(1+2.718281828459045**-(-1.57 + 20*(RED-SWIR)/(RED+SWIR) + 68.6*(GREEN-RED)/(GREEN+RED)))', {\n",
    "#             'SWIR': image.select('SR_B5'),\n",
    "#             'RED': image.select('SR_B3'),\n",
    "#             'GREEN': image.select('SR_B2')\n",
    "#         })\n",
    "    \n",
    "#     return image.addBands(flats.rename('flats'))\n",
    "\n",
    "#Updated 10/6/2022 - Band names changed for Collection 2\n",
    "\n",
    "\n",
    "#12/08/22 - adding CALIBRATED FLATS\n",
    "def addFLATSL7(image):\n",
    "    flats = ee.Image(0).expression(\n",
    "        '1/(1+2.718281828459045**-(1.51 + 12.5*(RED-SWIR)/(RED+SWIR) - 41.2*(NIR-RED)/(NIR+6*RED-7.5*BLUE+1)))', {\n",
    "            'SWIR': image.select('SR_B5'),\n",
    "            'NIR': image.select('SR_B4'),\n",
    "            'RED': image.select('SR_B3'),\n",
    "            'BLUE': image.select('SR_B1')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(flats.rename('flats'))\n",
    "\n",
    "def addFLATSL5(image):\n",
    "    flats = ee.Image(0).expression(\n",
    "        '1/(1+2.718281828459045**-(1.51 + 12.5*(0.972*(RED-SWIR)/(RED+SWIR)-0.008) - 41.2*(0.991*(NIR-RED)/(NIR+6*RED-7.5*BLUE+1)-0.0014)))', {\n",
    "            'SWIR': image.select('SR_B5'),\n",
    "            'NIR': image.select('SR_B4'),\n",
    "            'RED': image.select('SR_B3'),\n",
    "            'BLUE': image.select('SR_B1')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(flats.rename('flats'))\n",
    "\n",
    "\n",
    "def addFLATSL8(image):\n",
    "    flats = ee.Image(0).expression(\n",
    "        '1/(1+2.718281828459045**-(1.51 + 12.5*(0.841*(RED-SWIR)/(RED+SWIR) - 0.019) - 41.2*(0.771*(NIR-RED)/(NIR+6*RED-7.5*BLUE+1) + 0.011)))', {\n",
    "            'SWIR': image.select('SR_B6'),\n",
    "            'NIR': image.select('SR_B5'),\n",
    "            'RED': image.select('SR_B4'),\n",
    "            'BLUE': image.select('SR_B2')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(flats.rename('flats'))\n",
    "\n",
    "def addFLATSL9(image):\n",
    "    flats = ee.Image(0).expression(\n",
    "        '1/(1+2.718281828459045**-(1.51 + 12.5*(1.225*(RED-SWIR)/(RED+SWIR) + 0.096) - 41.2*(1.038* (NIR-RED)/(NIR+6*RED-7.5*BLUE+1) - 0.004)))', {\n",
    "            'SWIR': image.select('SR_B6'),\n",
    "            'NIR': image.select('SR_B5'),\n",
    "            'RED': image.select('SR_B4'),\n",
    "            'BLUE': image.select('SR_B2')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(flats.rename('flats'))\n",
    "\n",
    "##MASKING FLATS\n",
    "def maskFLATS(image):\n",
    "    mask1 = image.select('flats').lte(0.1) #less than or equal to 0.1 - change?\n",
    "    return image.updateMask(mask1)\n",
    "\n",
    "##ADDING NDVI (for min/max variables)\n",
    "def addL5ndvi(image):\n",
    "    ndvi = image.expression(\n",
    "        '(NIR-RED)/(RED+NIR)', {\n",
    "            'NIR': image.select('SR_B4'),\n",
    "            'RED': image.select('SR_B3'),\n",
    "            'GREEN': image.select('SR_B2')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(ndvi.rename('ndvi'))\n",
    "\n",
    "def addL8ndvi(image):\n",
    "    ndvi = image.expression(\n",
    "        '(NIR-RED)/(RED+NIR)', {\n",
    "            'NIR': image.select('SR_B5'),\n",
    "            'RED': image.select('SR_B4'),\n",
    "            'GREEN': image.select('SR_B3')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(ndvi.rename('ndvi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f954f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pixel extraction functions - addDate for dateless images/collections\n",
    "def addDate(image):\n",
    "    img_date = ee.Date(image.date())\n",
    "    img_date = ee.Number.parse(img_date.format('YYYYMMdd'))\n",
    "    return image.addBands(ee.Image(img_date).rename('imagedate').toInt())\n",
    "\n",
    "##For Landsat images:\n",
    "def rasterExtraction(image):\n",
    "    feature = image.sampleRegions(\n",
    "        collection = fc_all,\n",
    "        scale = 30,\n",
    "        tileScale = 16 #ADDED 10/6/2022 - make sure it doesn't affect results (see thread below)\n",
    "    )\n",
    "    return feature\n",
    "\n",
    "##FOR 10m DEM:\n",
    "def demExtraction(image):\n",
    "    feature = image.sampleRegions(\n",
    "        collection = fc_all,\n",
    "        scale = 10 \n",
    "    )\n",
    "    return feature\n",
    "\n",
    "##FOR 1m DEM:\n",
    "def dem1Extraction(image):\n",
    "    feature = image.sampleRegions(\n",
    "        collection = fc_all,\n",
    "        scale = 1, \n",
    "        tileScale = 16 #ADDED 11/7/2022\n",
    "\n",
    "    )\n",
    "    return feature\n",
    "\n",
    "#tileScale: https://gis.stackexchange.com/questions/373250/understanding-tilescale-in-earth-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94b7931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding DEM\n",
    "dem = ee.Image('USGS/3DEP/10m') ##This is 1/3 arc second, or 10 m.\n",
    "dem1 = ee.ImageCollection('USGS/3DEP/1m')\n",
    "\n",
    "##Set visualization parameters.\n",
    "dem_params = {\n",
    "    'min': 0,\n",
    "    'max': 4000,\n",
    "    'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5'],\n",
    "}\n",
    "\n",
    "Map.addLayer(dem, dem_params, '10m DEM')\n",
    "Map.addLayer(dem1, dem_params, '1m DEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbef1e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Calculating mean pixel values for time periods within each year\n",
    "\n",
    "##NOTE (11/7/22): got 1 m elevation extraction working, and want to consolidate all variables onto one df\n",
    "\n",
    "def monthly_Avg (collection, years):\n",
    "  avg = []\n",
    "  for year in years: #Originally had a for month in months subloop, with (month,month,'month') being a filter and set month\n",
    "      Monthly_avg = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "                              .filter(ee.Filter.calendarRange(5, 10, 'month')) \\\n",
    "                              .mean() \\\n",
    "                              .set({'year': year})\n",
    "      avg.append (Monthly_avg)\n",
    "  return ee.ImageCollection.fromImages(avg)\n",
    "\n",
    "##Months and years are lists\n",
    "\n",
    "years_ls5 = range(2000, 2012)\n",
    "years_ls7 = range(2012, 2013)\n",
    "years_ls8 = range(2013, 2021)\n",
    "years_dm = range(2000, 2021)\n",
    "\n",
    "months = range(5,11)\n",
    "months_daymet = range(1,12)\n",
    "\n",
    "ls5_collect = ee.ImageCollection(\n",
    "    'LANDSAT/LT05/C02/T1_L2'\n",
    ").filterBounds(fc_all).map(maskL8sr).map(addFLATSL5).map(maskFLATS).map(addL5ndvi)\n",
    "\n",
    "ls7_collect = ee.ImageCollection(\n",
    "    'LANDSAT/LE07/C02/T1_L2'\n",
    ").filterBounds(fc_all).map(maskL8sr).map(addFLATSL7).map(maskFLATS).map(addL5ndvi) ####SHOULD BE addFLATSL5\n",
    "\n",
    "#Note:Landsat datasets migrated to Collection 2\n",
    "\n",
    "ls8_collect = ee.ImageCollection(\n",
    "    'LANDSAT/LC08/C02/T1_L2'\n",
    ").filterBounds(fc_all).map(maskL8sr).map(addFLATSL8).map(maskFLATS).map(addL8ndvi)\n",
    "\n",
    "monthly_ls5 = monthly_Avg(ls5_collect, years = years_ls5)\n",
    "monthly_ls7 = monthly_Avg(ls7_collect, years = years_ls7)\n",
    "monthly_ls8 = monthly_Avg(ls8_collect, years = years_ls8)\n",
    "\n",
    "monthly_ls5.size().getInfo()\n",
    "\n",
    "##From stackexchange: calculating monthly averages across many years:\n",
    "#https://gis.stackexchange.com/questions/290892/google-earth-enginesst-by-month-per-year\n",
    "#https://gis.stackexchange.com/questions/426662/image-collection-monthly-averages-using-geemap-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2ea7a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_Avg (collection, years):\n",
    "  avg = []\n",
    "  for year in years: #Originally had a for month in months subloop, with (month,month,'month') being a filter and set month\n",
    "      Monthly_avg = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "                              .filter(ee.Filter.calendarRange(1, 12, 'month')) \\\n",
    "                              .mean() \\\n",
    "                              .set({'year': year})\n",
    "      avg.append (Monthly_avg)\n",
    "  return ee.ImageCollection.fromImages(avg)\n",
    "\n",
    "\n",
    "year_ls5 = year_Avg(ls5_collect, years = years_ls5)\n",
    "year_ls7 = year_Avg(ls7_collect, years = years_ls7)\n",
    "year_ls8 = year_Avg(ls8_collect, years = years_ls8)\n",
    "\n",
    "yearlist_5 = year_ls5.toList(year_ls5.size())\n",
    "yearlist_7 = year_ls7.toList(year_ls7.size())\n",
    "yearlist_8 = year_ls8.toList(year_ls8.size())\n",
    "\n",
    "def peak_Avg (collection, years):\n",
    "  avg = []\n",
    "  for year in years: #Originally had a for month in months subloop, with (month,month,'month') being a filter and set month\n",
    "      Monthly_avg = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "                              .filter(ee.Filter.calendarRange(8, 10, 'month')) \\\n",
    "                              .mean() \\\n",
    "                              .set({'year': year})\n",
    "      avg.append (Monthly_avg)\n",
    "  return ee.ImageCollection.fromImages(avg)\n",
    "\n",
    "peak_ls5 = peak_Avg(ls5_collect, years = years_ls5)\n",
    "peak_ls7 = peak_Avg(ls7_collect, years = years_ls7)\n",
    "peak_ls8 = peak_Avg(ls8_collect, years = years_ls8)\n",
    "\n",
    "peaklist_5 = peak_ls5.toList(peak_ls5.size())\n",
    "peaklist_7 = peak_ls7.toList(peak_ls7.size())\n",
    "peaklist_8 = peak_ls8.toList(peak_ls8.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53f9f87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab5e601cbf04836b263bd294f2706bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=107150.0, center=[31.539096, -81.422318], controls=(WidgetControl(options=['position', 'transparentâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_5 = monthly_ls5.toList(monthly_ls5.size())\n",
    "list_7 = monthly_ls7.toList(monthly_ls7.size())\n",
    "list_8 = monthly_ls8.toList(monthly_ls8.size())\n",
    "\n",
    "vis_param = {'min': 0, \n",
    "             'max': 0.2, \n",
    "             'bands': ['SR_B4', 'SR_B3', 'SR_B2'], \n",
    "             'gamma': 1.5}\n",
    "\n",
    "x= ee.Image(list_5.get(0))\n",
    "y= ee.Image(list_8.get(0))\n",
    "\n",
    "Map.addLayer(x, vis_param)\n",
    "\n",
    "Map.addLayer(fc_all)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cf895b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daymet\n",
    "def dm_Avg (collection, years):\n",
    "  avg = []\n",
    "  for year in years: #Originally had a for month in months subloop, with (month,month,'month') being a filter\n",
    "      Monthly_avg = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "                              .filter(ee.Filter.calendarRange(1, 12, 'month')) \\\n",
    "                              .mean() \\\n",
    "                              .set({'year': year})\n",
    "      avg.append (Monthly_avg)\n",
    "  return ee.ImageCollection.fromImages(avg)\n",
    "\n",
    "\n",
    "def peakdm_Avg (collection, years):\n",
    "  avg = []\n",
    "  for year in years: #Originally had a for month in months subloop, with (month,month,'month') being a filter\n",
    "      Monthly_avg = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "                              .filter(ee.Filter.calendarRange(8, 10, 'month')) \\\n",
    "                              .mean() \\\n",
    "                              .set({'year': year})\n",
    "      avg.append (Monthly_avg)\n",
    "  return ee.ImageCollection.fromImages(avg)\n",
    "\n",
    "daymet = ee.ImageCollection('NASA/ORNL/DAYMET_V4').filterBounds(fc_all)\n",
    "\n",
    "#Over year\n",
    "monthly_dm = dm_Avg(daymet, years = years_dm)\n",
    "dm_list = monthly_dm.toList(monthly_dm.size())\n",
    "\n",
    "#Peak biomass\n",
    "peak_dm = peakdm_Avg(daymet, years = years_dm)\n",
    "peakdm_list = peak_dm.toList(peak_dm.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb0ff3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elevation\n",
    "dem_vals = geemap.ee_to_pandas(demExtraction(dem)) ##10m dataset\n",
    "# dem_vals = geemap.ee_to_pandas(dem1.map(dem1Extraction).flatten()) ##ONE METER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With loop to cut out unnecessary code:\n",
    "years_l5 = range(2000, 2012)\n",
    "years_l7 = range(2012, 2013)\n",
    "years_l8 = range(2013, 2021)\n",
    "\n",
    "landsat5_list = []\n",
    "for i in range(len(years_l5)):\n",
    "    ls5_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(list_5.get(i))))\n",
    "    sample5 = ls5_x[ls5_x['Year'] == years_l5[i]]\n",
    "    landsat5_list.append(sample5) \n",
    "    \n",
    "landsat7_list = []\n",
    "for i in range(len(years_l7)):\n",
    "    ls7_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(list_7.get(i))))\n",
    "    sample7 = ls7_x[ls7_x['Year'] == years_l7[i]]\n",
    "    landsat7_list.append(sample7) \n",
    "    \n",
    "landsat8_list = []\n",
    "for i in range(len(years_l8)):\n",
    "    ls8_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(list_8.get(i))))\n",
    "    sample8 = ls8_x[ls8_x['Year'] == years_l8[i]]\n",
    "    landsat8_list.append(sample8) \n",
    "\n",
    "l5_extract = pd.concat(landsat5_list)\n",
    "l7_extract = pd.concat(landsat7_list)\n",
    "l8_extract = pd.concat(landsat8_list)\n",
    "\n",
    "landsat_extract = pd.concat([l5_extract,l7_extract,l8_extract])\n",
    "\n",
    "landsat_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yearly:\n",
    "years_l5 = range(2000, 2012)\n",
    "years_l7 = range(2012, 2013)\n",
    "years_l8 = range(2013, 2021)\n",
    "\n",
    "landsat5_list = []\n",
    "for i in range(len(years_l5)):\n",
    "    ls5_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(yearlist_5.get(i))))\n",
    "    sample5 = ls5_x[ls5_x['Year'] == years_l5[i]]\n",
    "    landsat5_list.append(sample5) \n",
    "    \n",
    "landsat7_list = []\n",
    "for i in range(len(years_l7)):\n",
    "    ls7_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(yearlist_7.get(i))))\n",
    "    sample7 = ls7_x[ls7_x['Year'] == years_l7[i]]\n",
    "    landsat7_list.append(sample7) \n",
    "    \n",
    "landsat8_list = []\n",
    "for i in range(len(years_l8)):\n",
    "    ls8_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(yearlist_8.get(i))))\n",
    "    sample8 = ls8_x[ls8_x['Year'] == years_l8[i]]\n",
    "    landsat8_list.append(sample8) \n",
    "\n",
    "l5_extract = pd.concat(landsat5_list)\n",
    "l7_extract = pd.concat(landsat7_list)\n",
    "l8_extract = pd.concat(landsat8_list)\n",
    "\n",
    "year_extract = pd.concat([l5_extract,l7_extract,l8_extract])\n",
    "\n",
    "year_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With loop to cut out unnecessary code:\n",
    "years_l5 = range(2000, 2012)\n",
    "years_l7 = range(2012, 2013)\n",
    "years_l8 = range(2013, 2021)\n",
    "\n",
    "landsat5_list = []\n",
    "for i in range(len(years_l5)):\n",
    "    ls5_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(peaklist_5.get(i))))\n",
    "    sample5 = ls5_x[ls5_x['Year'] == years_l5[i]]\n",
    "    landsat5_list.append(sample5) \n",
    "    \n",
    "landsat7_list = []\n",
    "for i in range(len(years_l7)):\n",
    "    ls7_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(peaklist_7.get(i))))\n",
    "    sample7 = ls7_x[ls7_x['Year'] == years_l7[i]]\n",
    "    landsat7_list.append(sample7) \n",
    "    \n",
    "landsat8_list = []\n",
    "for i in range(len(years_l8)):\n",
    "    ls8_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(peaklist_8.get(i))))\n",
    "    sample8 = ls8_x[ls8_x['Year'] == years_l8[i]]\n",
    "    landsat8_list.append(sample8) \n",
    "\n",
    "l5_extract = pd.concat(landsat5_list)\n",
    "l7_extract = pd.concat(landsat7_list)\n",
    "l8_extract = pd.concat(landsat8_list)\n",
    "\n",
    "peak_extract = pd.concat([l5_extract,l7_extract,l8_extract])\n",
    "\n",
    "peak_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f454d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daymet for loop and elevation\n",
    "years_dm = range(2000, 2021)\n",
    "\n",
    "daymet_list = []\n",
    "for i in range(len(years_dm)):\n",
    "    dm_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(dm_list.get(i))))\n",
    "    sampledm = dm_x[dm_x['Year'] == years_dm[i]]\n",
    "    daymet_list.append(sampledm) \n",
    "    \n",
    "daymet_extract = pd.concat(daymet_list)\n",
    "\n",
    "daymet_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daymet peak time\n",
    "years_dm = range(2000, 2021)\n",
    "\n",
    "daymet_list = []\n",
    "for i in range(len(years_dm)):\n",
    "    dm_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(peakdm_list.get(i))))\n",
    "    sampledm = dm_x[dm_x['Year'] == years_dm[i]]\n",
    "    daymet_list.append(sampledm) \n",
    "    \n",
    "peakdaymet_extract = pd.concat(daymet_list)\n",
    "\n",
    "peakdaymet_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caff987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final steps - extra rows in merge?\n",
    "\n",
    "#MayOct and elevation\n",
    "dfx = pd.merge(landsat_extract, dem_vals, how = 'left')\n",
    "\n",
    "#dfx and AugOct\n",
    "peak_extract.rename(\n",
    "    columns={\n",
    "        'SR_B1':'SR_B1_peak','SR_B2':'SR_B2_peak','SR_B3':'SR_B3_peak','SR_B4':'SR_B4_peak', 'SR_B5':'SR_B5_peak',\n",
    "        'SR_B6':'SR_B6_peak', 'SR_B7':'SR_B7_peak', 'flats':'flats_peak'\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "dfx1 = pd.merge(dfx, peak_extract, on = ['Plant_Biomass', 'Plot', 'Zone', 'Site', 'Year'], how='outer',\n",
    "                suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')\n",
    "\n",
    "#dfx1 and year_extract\n",
    "\n",
    "year_extract.rename(\n",
    "    columns={\n",
    "        'SR_B1':'SR_B1_year','SR_B2':'SR_B2_year','SR_B3':'SR_B3_year','SR_B4':'SR_B4_year', 'SR_B5':'SR_B5_year',\n",
    "        'SR_B6':'SR_B6_year', 'SR_B7':'SR_B7_year', 'flats':'flats_year'\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "dfx2 = pd.merge(dfx1, year_extract, on = ['Plant_Biomass', 'Plot', 'Zone', 'Site', 'Year'], how='outer',\n",
    "                suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')\n",
    "\n",
    "\n",
    "#dfx2 and daymet mayoct\n",
    "dfx3 = pd.merge(dfx2, daymet_extract, on = ['Plant_Biomass', 'Plot', 'Zone', 'Site', 'Year'], how='right')\n",
    "\n",
    "#dfx3 and daymet peak\n",
    "peakdaymet_extract.rename(\n",
    "    columns={\n",
    "        'swe':'swe_peak','tmax':'tmax_peak','tmin':'tmin_peak','srad':'srad_peak', 'vp':'vp_peak',\n",
    "        'prcp':'prcp_peak', 'dayl':'dayl_peak'\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "df = pd.merge(dfx3, peakdaymet_extract, on = ['Plant_Biomass', 'Plot', 'Zone', 'Site', 'Year'], how='right',\n",
    "              suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2bb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in daymet_extract.columns:\n",
    "    print(col)\n",
    "    \n",
    "    ##EXPORT\n",
    "out_dir = os.path.expanduser('~/Downloads')\n",
    "out_csv = os.path.join(out_dir, 'testx.csv')\n",
    "# df.to_csv(out_csv, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bands and indices\n",
    "df['Sensor'] = np.where(df['Year']<2013, 'Landsat 5', 'Landsat 8') ##make sure no other sensors are being used\n",
    "\n",
    "df.loc[df['Year'] == 2012, 'Sensor'] = 'Landsat 7'\n",
    "\n",
    "df['ndvi'] = np.where(df['Sensor'] == 'Landsat 8', (df['SR_B5']-df['SR_B4'])/(df['SR_B5']+df['SR_B4']), \\\n",
    "                      (df['SR_B4']-df['SR_B3'])/(df['SR_B4']+df['SR_B3'])) \n",
    "##ndvi conditional based on whether sensor is Landsat-5 or 8\n",
    "\n",
    "df['Blue_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B2'], df['SR_B1'])\n",
    "df['Green_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B3'], df['SR_B2'])\n",
    "df['Red_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B4'], df['SR_B3'])\n",
    "df['NIR_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B5'], df['SR_B4'])\n",
    "df['SWIR1_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B6'], df['SR_B5'])\n",
    "df['SWIR2_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B7'], df['SR_B7'])\n",
    "\n",
    "##Variables from Byrd et al. 2018 (make sure calculations are accurate):\n",
    "df['savi'] = ((df['NIR_band']-df['Red_band'])*1.5)/(df['NIR_band']+df['Red_band']+0.5)\n",
    "df['wdrvi5'] = (0.5*df['NIR_band']-df['Red_band'])/(0.5*df['NIR_band']+df['Red_band'])\n",
    "df['nd_r_g'] = (df['Red_band']-df['Green_band'])/(df['Red_band']+df['Green_band'])\n",
    "df['nd_g_b'] = (df['Green_band']-df['Blue_band'])/(df['Green_band']+df['Blue_band'])\n",
    "df['nd_swir2_nir'] = (df['SWIR2_band']-df['NIR_band'])/(df['SWIR2_band']+df['NIR_band'])\n",
    "df['nd_swir2_r'] = (df['SWIR2_band']-df['Red_band'])/(df['SWIR2_band']+df['Red_band'])\n",
    "\n",
    "display(df)\n",
    "\n",
    "##EXPORT\n",
    "out_dir = os.path.expanduser('~/Downloads')\n",
    "out_csv = os.path.join(out_dir, 'df_mayoct.csv')\n",
    "# df.to_csv(out_csv, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4920aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ndvi_year'] = np.where(df['Sensor'] == 'Landsat 8', (df['SR_B5_year']-df['SR_B4_year'])/(df['SR_B5_year']+df['SR_B4_year']), \\\n",
    "                      (df['SR_B4_year']-df['SR_B3_year'])/(df['SR_B4_year']+df['SR_B3_year'])) \n",
    "##ndvi conditional based on whether sensor is Landsat-5 or 8\n",
    "\n",
    "df['Blue_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B2_year'], df['SR_B1_year'])\n",
    "df['Green_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B3_year'], df['SR_B2_year'])\n",
    "df['Red_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B4_year'], df['SR_B3_year'])\n",
    "df['NIR_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B5_year'], df['SR_B4_year'])\n",
    "df['SWIR1_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B6_year'], df['SR_B5_year'])\n",
    "df['SWIR2_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B7_year'], df['SR_B7_year'])\n",
    "\n",
    "##Variables from Byrd et al. 2018 (make sure calculations are accurate):\n",
    "df['savi_year'] = ((df['NIR_band_year']-df['Red_band_year'])*1.5)/(df['NIR_band_year']+df['Red_band_year']+0.5)\n",
    "df['wdrvi5_year'] = (0.5*df['NIR_band_year']-df['Red_band_year'])/(0.5*df['NIR_band_year']+df['Red_band_year'])\n",
    "df['nd_r_g_year'] = (df['Red_band_year']-df['Green_band_year'])/(df['Red_band_year']+df['Green_band_year'])\n",
    "df['nd_g_b_year'] = (df['Green_band_year']-df['Blue_band_year'])/(df['Green_band_year']+df['Blue_band_year'])\n",
    "df['nd_swir2_nir_year'] = (df['SWIR2_band_year']-df['NIR_band_year'])/(df['SWIR2_band_year']+df['NIR_band_year'])\n",
    "df['nd_swir2_r_year'] = (df['SWIR2_band_year']-df['Red_band_year'])/(df['SWIR2_band_year']+df['Red_band_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ndvi_peak'] = np.where(df['Sensor'] == 'Landsat 8', (df['SR_B5_peak']-df['SR_B4_peak'])/(df['SR_B5_peak']+df['SR_B4_peak']), \\\n",
    "                      (df['SR_B4_peak']-df['SR_B3_peak'])/(df['SR_B4_peak']+df['SR_B3_peak'])) \n",
    "##ndvi conditional based on whether sensor is Landsat-5 or 8\n",
    "\n",
    "df['Blue_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B2_peak'], df['SR_B1_peak'])\n",
    "df['Green_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B3_peak'], df['SR_B2_peak'])\n",
    "df['Red_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B4_peak'], df['SR_B3_peak'])\n",
    "df['NIR_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B5_peak'], df['SR_B4_peak'])\n",
    "df['SWIR1_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B6_peak'], df['SR_B5_peak'])\n",
    "df['SWIR2_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B7_peak'], df['SR_B7_peak'])\n",
    "\n",
    "##Variables from Byrd et al. 2018 (make sure calculations are accurate):\n",
    "df['savi_peak'] = ((df['NIR_band_peak']-df['Red_band_peak'])*1.5)/(df['NIR_band_peak']+df['Red_band_peak']+0.5)\n",
    "df['wdrvi5_peak'] = (0.5*df['NIR_band_peak']-df['Red_band_peak'])/(0.5*df['NIR_band_peak']+df['Red_band_peak'])\n",
    "df['nd_r_g_peak'] = (df['Red_band_peak']-df['Green_band_peak'])/(df['Red_band_peak']+df['Green_band_peak'])\n",
    "df['nd_g_b_peak'] = (df['Green_band_peak']-df['Blue_band_peak'])/(df['Green_band_peak']+df['Blue_band_peak'])\n",
    "df['nd_swir2_nir_peak'] = (df['SWIR2_band_peak']-df['NIR_band_peak'])/(df['SWIR2_band_peak']+df['NIR_band_peak'])\n",
    "df['nd_swir2_r_peak'] = (df['SWIR2_band_peak']-df['Red_band_peak'])/(df['SWIR2_band_peak']+df['Red_band_peak'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://stackoverflow.com/questions/18557860/how-to-create-a-list-with-a-range-of-years\n",
    "\n",
    "##WITH VARIABLE YEAR IN FILE NAME\n",
    "\n",
    "df = df[df['Red_band'].notna()]\n",
    "df = df[df['SR_B4_peak'].notna()]\n",
    "df = df[df['SR_B4_year'].notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##EXPORT\n",
    "out_dir = os.path.expanduser('~/Downloads')\n",
    "out_csv = os.path.join(out_dir, 'df_testx.csv')\n",
    "# df.to_csv(out_csv, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
