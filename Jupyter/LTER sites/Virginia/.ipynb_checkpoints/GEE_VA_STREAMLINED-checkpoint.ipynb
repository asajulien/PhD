{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4046d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "from IPython.display import display\n",
    "import ee\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c985e47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Date</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>liveMass</th>\n",
       "      <th>Sample size</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LTE-MP-LPA</td>\n",
       "      <td>1999-06-30</td>\n",
       "      <td>-70.842468</td>\n",
       "      <td>42.731743</td>\n",
       "      <td>578.075000</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LTE-MP-LPA</td>\n",
       "      <td>1999-07-24</td>\n",
       "      <td>-70.842468</td>\n",
       "      <td>42.731743</td>\n",
       "      <td>486.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LTE-MP-LPA</td>\n",
       "      <td>1999-08-27</td>\n",
       "      <td>-70.842468</td>\n",
       "      <td>42.731743</td>\n",
       "      <td>389.725000</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LTE-MP-LPA</td>\n",
       "      <td>1999-09-22</td>\n",
       "      <td>-70.842468</td>\n",
       "      <td>42.731743</td>\n",
       "      <td>441.625000</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LTE-MP-LPA</td>\n",
       "      <td>1999-10-26</td>\n",
       "      <td>-70.842468</td>\n",
       "      <td>42.731743</td>\n",
       "      <td>211.300000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>LTE-MP-LPP</td>\n",
       "      <td>2020-08-02</td>\n",
       "      <td>-70.842918</td>\n",
       "      <td>42.730953</td>\n",
       "      <td>1009.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>LTE-MP-LPP</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>-70.842918</td>\n",
       "      <td>42.730953</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>LTE-MP-LPP</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>-70.842918</td>\n",
       "      <td>42.730953</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>LTE-MP-LPP</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>-70.842918</td>\n",
       "      <td>42.730953</td>\n",
       "      <td>687.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>LTE-MP-LPP</td>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>-70.842918</td>\n",
       "      <td>42.730953</td>\n",
       "      <td>892.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Site       Date  Longitude   Latitude     liveMass  Sample size  \\\n",
       "0    LTE-MP-LPA 1999-06-30 -70.842468  42.731743   578.075000            4   \n",
       "1    LTE-MP-LPA 1999-07-24 -70.842468  42.731743   486.750000            4   \n",
       "2    LTE-MP-LPA 1999-08-27 -70.842468  42.731743   389.725000            4   \n",
       "3    LTE-MP-LPA 1999-09-22 -70.842468  42.731743   441.625000            4   \n",
       "4    LTE-MP-LPA 1999-10-26 -70.842468  42.731743   211.300000            4   \n",
       "..          ...        ...        ...        ...          ...          ...   \n",
       "210  LTE-MP-LPP 2020-08-02 -70.842918  42.730953  1009.666667            6   \n",
       "211  LTE-MP-LPP 2021-05-11 -70.842918  42.730953    57.000000            6   \n",
       "212  LTE-MP-LPP 2021-06-22 -70.842918  42.730953   462.000000            6   \n",
       "213  LTE-MP-LPP 2021-07-27 -70.842918  42.730953   687.333333            6   \n",
       "214  LTE-MP-LPP 2021-09-12 -70.842918  42.730953   892.666667            6   \n",
       "\n",
       "     Month  Year  \n",
       "0        6  1999  \n",
       "1        7  1999  \n",
       "2        8  1999  \n",
       "3        9  1999  \n",
       "4       10  1999  \n",
       "..     ...   ...  \n",
       "210      8  2020  \n",
       "211      5  2021  \n",
       "212      6  2021  \n",
       "213      7  2021  \n",
       "214      9  2021  \n",
       "\n",
       "[215 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>locationID</th>\n",
       "      <th>Transect</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>liveMass</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>37.167147</td>\n",
       "      <td>-75.940768</td>\n",
       "      <td>46.72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>37.174764</td>\n",
       "      <td>-75.942417</td>\n",
       "      <td>399.68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>37.180976</td>\n",
       "      <td>-75.940766</td>\n",
       "      <td>441.68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>37.287699</td>\n",
       "      <td>-75.929487</td>\n",
       "      <td>669.60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>37.345970</td>\n",
       "      <td>-75.901065</td>\n",
       "      <td>875.52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>37.287875</td>\n",
       "      <td>-75.929008</td>\n",
       "      <td>96.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>37.167768</td>\n",
       "      <td>-75.944280</td>\n",
       "      <td>26.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>37.449973</td>\n",
       "      <td>-75.671952</td>\n",
       "      <td>279.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>37.396051</td>\n",
       "      <td>-75.876056</td>\n",
       "      <td>255.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>37.449973</td>\n",
       "      <td>-75.671952</td>\n",
       "      <td>382.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  locationID Transect   Latitude  Longitude  liveMass  N\n",
       "0     1999           1        A  37.167147 -75.940768     46.72  2\n",
       "1     1999           1        A  37.174764 -75.942417    399.68  2\n",
       "2     1999           1        A  37.180976 -75.940766    441.68  2\n",
       "3     1999           1        A  37.287699 -75.929487    669.60  2\n",
       "4     1999           1        A  37.345970 -75.901065    875.52  2\n",
       "...    ...         ...      ...        ...        ...       ... ..\n",
       "1003  2017           3        B  37.287875 -75.929008     96.08  2\n",
       "1004  2017           3        C  37.167768 -75.944280     26.56  2\n",
       "1005  2017           3        C  37.449973 -75.671952    279.36  1\n",
       "1006  2018           1        C  37.396051 -75.876056    255.04  1\n",
       "1007  2018           3        C  37.449973 -75.671952    382.56  1\n",
       "\n",
       "[1008 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ee.Authenticate()\n",
    "#geemap.update_package()\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "Map = geemap.Map(center=[37.395746,-75.876094], zoom=10)\n",
    "\n",
    "##Adding every plot coordinate\n",
    "allplots_fc= pd.read_csv('C:/Users/arj26323/Documents/Data/Biomass datasets/Virginia/Coordinates and biomass/va_allpoints.csv')\n",
    "allplots_fc = allplots_fc[allplots_fc['liveMass'].notna()]\n",
    "allplots_fc = allplots_fc[allplots_fc['Latitude'].notna()]\n",
    "allplots_fc = allplots_fc.drop(columns = ['deadMass', 'collectDate', 'totalMass', 'Ell', 'MSL', 'latitude', 'longitude'])\n",
    "\n",
    "##Group df1 and average (midpoint) the replicates (a/b)\n",
    "df_temp=allplots_fc.copy()\n",
    "\n",
    "df_temp = df_temp.groupby(['Year','locationID','Transect','Latitude','Longitude'],as_index = False).aggregate(\n",
    "    {\n",
    "        'liveMass':[np.mean, np.size]\n",
    "    }\n",
    ")\n",
    "\n",
    "df_temp.columns = [\n",
    "    'Year','locationID','Transect','Latitude','Longitude','liveMass','N'\n",
    "]\n",
    "##Adding every plot coordinate\n",
    "s_patens = pd.read_csv('C:/Users/arj26323/Documents/Data/Biomass datasets/Massachusetts/LTE-MP-LPP-biomass.csv')\n",
    "s_alterniflora = pd.read_csv('C:/Users/arj26323/Documents/Data/Biomass datasets/Massachusetts/LTE-MP-LPA-biomass.csv')\n",
    "\n",
    "s_patens['Latitude'] = 42.730953216553\n",
    "s_patens['Longitude'] = -70.842918395996\n",
    "\n",
    "s_alterniflora['Latitude'] = 42.731742858887\n",
    "s_alterniflora['Longitude'] = -70.842468261719\n",
    "\n",
    "s_patens.rename(columns={'LIVE biomass':'liveMass'}, inplace=True)\n",
    "s_alterniflora.rename(columns={'MEAN BIOMASS':'liveMass'}, inplace=True)\n",
    "\n",
    "df = pd.concat([s_patens, s_alterniflora])\n",
    "\n",
    "df['Date'] = pd.to_datetime(df[['YEAR', 'MONTH', 'DAY']])\n",
    "\n",
    "# df = df[df['TRT'] == 'C'] ##Remove fertilized plots? Since they won't represent the pixel well. But they might?\n",
    "\n",
    "dfx =  df.groupby(['SITE', 'Date'], as_index = False).aggregate(\n",
    "    {\n",
    "        'Longitude':[np.mean], 'Latitude':[np.mean], 'liveMass':[np.mean, np.size], \n",
    "        'MONTH':'first', 'YEAR':'first'\n",
    "    }\n",
    ") \n",
    "\n",
    "dfx.columns = [\n",
    "    'Site','Date','Longitude','Latitude','liveMass', 'Sample size','Month', 'Year'\n",
    "]\n",
    "\n",
    "\n",
    "dfx.loc[dfx['Site'] == 'LTE-MP-LPP', 'Latitude'] = 42.730953216553\n",
    "dfx.loc[dfx['Site'] == 'LTE-MP-LPP', 'Longitude'] = -70.842918395996\n",
    "\n",
    "dfx.loc[dfx['Site'] == 'LTE-MP-LPA', 'Latitude'] = 42.731742858887\n",
    "dfx.loc[dfx['Site'] == 'LTE-MP-LPA', 'Longitude'] = -70.842468261719\n",
    "\n",
    "\n",
    "display(dfx) ##Grouped by site and date; average biomass\n",
    "\n",
    "# dfxend = dfx[dfx['Month'] == 9]\n",
    "# dfxend\n",
    "\n",
    "##NOTE: Structure of data extraction will have to be diff from VA/GA - lag variables/month sampled will change FOR EACH ROW\n",
    "##in the current dataset (since samlping occurs in different months for each row). Not exactly sure how to do this yet.\n",
    "\n",
    "fc_all = geemap.pandas_to_ee(dfx, latitude = 'Latitude', longitude = 'Longitude')\n",
    "\n",
    "allplots_fc = df_temp\n",
    "\n",
    "display(allplots_fc)\n",
    "\n",
    "fc_all = geemap.pandas_to_ee(allplots_fc, latitude = \"Latitude\", longitude = \"Longitude\")\n",
    "\n",
    "Map.addLayer(fc_all, {}, \"fc_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7698ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to cloud mask from the pixel_qa band of Landsat 5/8 SR data.\n",
    "\n",
    "def maskL8sr(image):\n",
    "    qaMask = image.select('QA_PIXEL').bitwiseAnd(int('11111', 2)).eq(0)\n",
    "    saturationMask = image.select('QA_RADSAT').eq(0)\n",
    "    # Apply the scaling factors to the appropriate bands.\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
    "    # Replace the original bands with the scaled ones and apply the masks.\n",
    "    return image.addBands(opticalBands, None, True) \\\n",
    "    .addBands(thermalBands, None, True) \\\n",
    "    .updateMask(qaMask) \\\n",
    "    .updateMask(saturationMask)\n",
    "\n",
    "#NOTE 10/6/2022 - This has been updated for Landsat Collection 2 https://www.usgs.gov/landsat-missions/landsat-collection-2\n",
    "#Scaling factors: https://www.usgs.gov/landsat-missions/landsat-collection-2-level-2-science-products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7546ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TIDAL FILTERING; from Narron et al. 2022\n",
    "##Utilizes L8 bands 4 and 6 for NDWI, and bands 3 and 4 (for pheno)\n",
    "##Does it work for Landsat 5?\n",
    "\n",
    "def addFLATS(image):\n",
    "    flats = ee.Image(0).expression(\n",
    "        '1/(1+2.718281828459045**-(-1.57 + 20*(RED-SWIR)/(RED+SWIR) + 68.6*(GREEN-RED)/(GREEN+RED)))', {\n",
    "            'SWIR': image.select('SR_B6'),\n",
    "            'RED': image.select('SR_B4'),\n",
    "            'GREEN': image.select('SR_B3')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(flats.rename('flats'))\n",
    "\n",
    "def addFLATSL5(image):\n",
    "    flats = ee.Image(0).expression(\n",
    "        '1/(1+2.718281828459045**-(-1.57 + 20*(RED-SWIR)/(RED+SWIR) + 68.6*(GREEN-RED)/(GREEN+RED)))', {\n",
    "            'SWIR': image.select('SR_B5'),\n",
    "            'RED': image.select('SR_B3'),\n",
    "            'GREEN': image.select('SR_B2')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(flats.rename('flats'))\n",
    "\n",
    "#Updated 10/6/2022 - Band names changed for Collection 2\n",
    "\n",
    "##MASKING FLATS\n",
    "def maskFLATS(image):\n",
    "    mask1 = image.select('flats').lte(0.1) #less than or equal to 0.1 - change?\n",
    "    return image.updateMask(mask1)\n",
    "\n",
    "##ADDING NDVI (for min/max variables)\n",
    "def addL5ndvi(image):\n",
    "    ndvi = image.expression(\n",
    "        '(NIR-RED)/(RED+NIR)', {\n",
    "            'NIR': image.select('SR_B4'),\n",
    "            'RED': image.select('SR_B3'),\n",
    "            'GREEN': image.select('SR_B2')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(ndvi.rename('ndvi'))\n",
    "\n",
    "def addL8ndvi(image):\n",
    "    ndvi = image.expression(\n",
    "        '(NIR-RED)/(RED+NIR)', {\n",
    "            'NIR': image.select('SR_B5'),\n",
    "            'RED': image.select('SR_B4'),\n",
    "            'GREEN': image.select('SR_B3')\n",
    "        })\n",
    "    \n",
    "    return image.addBands(ndvi.rename('ndvi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94930c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pixel extraction functions - addDate for dateless images/collections\n",
    "def addDate(image):\n",
    "    img_date = ee.Date(image.date())\n",
    "    img_date = ee.Number.parse(img_date.format('YYYYMMdd'))\n",
    "    return image.addBands(ee.Image(img_date).rename('imagedate').toInt())\n",
    "\n",
    "##For Landsat images:\n",
    "def rasterExtraction(image):\n",
    "    feature = image.sampleRegions(\n",
    "        collection = fc_all,\n",
    "        scale = 30,\n",
    "        tileScale = 8 #ADDED 10/6/2022 - make sure it doesn't affect results\n",
    "\n",
    "    )\n",
    "    return feature\n",
    "\n",
    "##FOR 10m DEM:\n",
    "def demExtraction(image):\n",
    "    feature = image.sampleRegions(\n",
    "        collection = fc_all,\n",
    "        scale = 10 \n",
    "    )\n",
    "    return feature\n",
    "\n",
    "##FOR 1m DEM:\n",
    "def dem1Extraction(image):\n",
    "    feature = image.sampleRegions(\n",
    "        collection = fc_all,\n",
    "        scale = 1 \n",
    "    )\n",
    "    return feature\n",
    "\n",
    "#tileScale: https://gis.stackexchange.com/questions/373250/understanding-tilescale-in-earth-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae26c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding DEM\n",
    "dem = ee.Image('USGS/3DEP/10m') ##This is 1/3 arc second, or 10 m.\n",
    "dem1 = ee.ImageCollection('USGS/3DEP/1m')\n",
    "\n",
    "##Set visualization parameters.\n",
    "dem_params = {\n",
    "    'min': 0,\n",
    "    'max': 4000,\n",
    "    'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5'],\n",
    "}\n",
    "\n",
    "Map.addLayer(dem, dem_params, '10m DEM')\n",
    "Map.addLayer(dem1, dem_params, '1m DEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0363265c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Calculating mean pixel values for time periods within each year\n",
    "\n",
    "def monthly_Avg (collection, years):\n",
    "  avg = []\n",
    "  for year in years: #Originally had a for month in months subloop, with (month,month,'month') being a filter and set month\n",
    "      Monthly_avg = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "                              .filter(ee.Filter.calendarRange(5, 10, 'month')) \\\n",
    "                              .mean() \\\n",
    "                              .set({'year': year})\n",
    "      avg.append (Monthly_avg)\n",
    "  return ee.ImageCollection.fromImages(avg)\n",
    "\n",
    "## Compute monthly averages\n",
    "# monthly_sowing_Avg = monthly_Avg (ndvi_sowSeason, years, sowingMonths)\n",
    "\n",
    "##Months and years are lists\n",
    "\n",
    "years_ls5 = range(1999, 2012)\n",
    "years_ls7 = range(2012, 2013)\n",
    "years_ls8 = range(2013, 2021)\n",
    "years_dm = range(2000, 2021)\n",
    "\n",
    "months = range(5,11)\n",
    "months_daymet = range(1,12)\n",
    "\n",
    "#Note:Landsat datasets migrated to Collection 2\n",
    "\n",
    "ls5_collect = ee.ImageCollection(\n",
    "    'LANDSAT/LT05/C02/T1_L2'\n",
    ").filterBounds(fc_all).map(maskL8sr).map(addFLATSL5).map(maskFLATS).map(addL5ndvi) ##MIGRATE TO COLLECTION 2 DATA\n",
    "\n",
    "ls7_collect = ee.ImageCollection(\n",
    "    'LANDSAT/LE07/C02/T1_L2'\n",
    ").filterBounds(fc_all).map(maskL8sr).map(addFLATSL5).map(maskFLATS).map(addL5ndvi) ##MIGRATE TO COLLECTION 2 DATA\n",
    "\n",
    "ls8_collect = ee.ImageCollection(\n",
    "    'LANDSAT/LC08/C02/T1_L2'\n",
    ").filterBounds(fc_all).map(maskL8sr).map(addFLATS).map(maskFLATS).map(addL8ndvi) ##NEW L8 DATASET: \"LANDSAT/LC08/C02/T1_L2\"\n",
    "\n",
    "monthly_ls5 = monthly_Avg(ls5_collect, years = years_ls5)\n",
    "monthly_ls7 = monthly_Avg(ls7_collect, years = years_ls7)\n",
    "monthly_ls8 = monthly_Avg(ls8_collect, years = years_ls8)\n",
    "\n",
    "monthly_ls5.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfad053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_Avg (collection, years):\n",
    "  avg = []\n",
    "  for year in years: #Originally had a for month in months subloop, with (month,month,'month') being a filter and set month\n",
    "      Monthly_avg = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "                              .filter(ee.Filter.calendarRange(1, 12, 'month')) \\\n",
    "                              .mean() \\\n",
    "                              .set({'year': year})\n",
    "      avg.append (Monthly_avg)\n",
    "  return ee.ImageCollection.fromImages(avg)\n",
    "\n",
    "\n",
    "year_ls5 = year_Avg(ls5_collect, years = years_ls5)\n",
    "year_ls7 = year_Avg(ls7_collect, years = years_ls7)\n",
    "year_ls8 = year_Avg(ls8_collect, years = years_ls8)\n",
    "\n",
    "yearlist_5 = year_ls5.toList(year_ls5.size())\n",
    "yearlist_7 = year_ls7.toList(year_ls7.size())\n",
    "yearlist_8 = year_ls8.toList(year_ls8.size())\n",
    "\n",
    "#PEAK average - different in MA than in GA\n",
    "def peak_Avg (collection, years):\n",
    "  avg = []\n",
    "  for year in years: #Originally had a for month in months subloop, with (month,month,'month') being a filter and set month\n",
    "      Monthly_avg = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "                              .filter(ee.Filter.calendarRange(7, 9, 'month')) \\\n",
    "                              .mean() \\\n",
    "                              .set({'year': year})\n",
    "      avg.append (Monthly_avg)\n",
    "  return ee.ImageCollection.fromImages(avg)\n",
    "\n",
    "peak_ls5 = peak_Avg(ls5_collect, years = years_ls5)\n",
    "peak_ls7 = peak_Avg(ls7_collect, years = years_ls7)\n",
    "peak_ls8 = peak_Avg(ls8_collect, years = years_ls8)\n",
    "\n",
    "peaklist_5 = peak_ls5.toList(peak_ls5.size())\n",
    "peaklist_7 = peak_ls7.toList(peak_ls7.size())\n",
    "peaklist_8 = peak_ls8.toList(peak_ls8.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc71a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daymet\n",
    "\n",
    "def dm_Avg (collection, years):\n",
    "  avg = []\n",
    "  for year in years: #Originally had a for month in months subloop, with (month,month,'month') being a filter\n",
    "      Monthly_avg = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "                              .filter(ee.Filter.calendarRange(1, 12, 'month')) \\\n",
    "                              .mean() \\\n",
    "                              .set({'year': year})\n",
    "      avg.append (Monthly_avg)\n",
    "  return ee.ImageCollection.fromImages(avg)\n",
    "\n",
    "\n",
    "#PEAK average - different in MA than in GA\n",
    "def peakdm_Avg (collection, years):\n",
    "  avg = []\n",
    "  for year in years: #Originally had a for month in months subloop, with (month,month,'month') being a filter\n",
    "      Monthly_avg = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "                              .filter(ee.Filter.calendarRange(7, 9, 'month')) \\\n",
    "                              .mean() \\\n",
    "                              .set({'year': year})\n",
    "      avg.append (Monthly_avg)\n",
    "  return ee.ImageCollection.fromImages(avg)\n",
    "\n",
    "daymet = ee.ImageCollection('NASA/ORNL/DAYMET_V4').filterBounds(fc_all)\n",
    "\n",
    "#Over year\n",
    "monthly_dm = dm_Avg(daymet, years = years_dm)\n",
    "dm_list = monthly_dm.toList(monthly_dm.size())\n",
    "\n",
    "#Peak biomass\n",
    "peak_dm = peakdm_Avg(daymet, years = years_dm)\n",
    "peakdm_list = peak_dm.toList(peak_dm.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47bcd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elevation\n",
    "dem_vals = geemap.ee_to_pandas(demExtraction(dem)) ##10m dataset\n",
    "# dem_vals = geemap.ee_to_pandas(dem1.map(dem1Extraction).flatten()) ##ONE METER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be6dcb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_5 = monthly_ls5.toList(monthly_ls5.size())\n",
    "list_7 = monthly_ls7.toList(monthly_ls7.size())\n",
    "list_8 = monthly_ls8.toList(monthly_ls8.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fa48dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Monthly/yearly extraction - NOTE: Takes a while to run\n",
    "##SUBSET BY YEAR\n",
    "\n",
    "dem_vals = geemap.ee_to_pandas(demExtraction(dem)) ##10m dataset\n",
    "# dem_vals = geemap.ee_to_pandas(dem1.map(dem1Extraction).flatten()) ##ONE METER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With loop to cut out unnecessary code:\n",
    "years_l5 = range(2000, 2012)\n",
    "years_l7 = range(2012, 2013)\n",
    "years_l8 = range(2013, 2021)\n",
    "\n",
    "landsat5_list = []\n",
    "for i in range(len(years_l5)):\n",
    "    ls5_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(list_5.get(i))))\n",
    "    sample5 = ls5_x[ls5_x['Year'] == years_l5[i]]\n",
    "    landsat5_list.append(sample5) \n",
    "    \n",
    "landsat7_list = []\n",
    "for i in range(len(years_l7)):\n",
    "    ls7_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(list_7.get(i))))\n",
    "    sample7 = ls7_x[ls7_x['Year'] == years_l7[i]]\n",
    "    landsat7_list.append(sample7) \n",
    "    \n",
    "landsat8_list = []\n",
    "for i in range(len(years_l8)):\n",
    "    ls8_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(list_8.get(i))))\n",
    "    sample8 = ls8_x[ls8_x['Year'] == years_l8[i]]\n",
    "    landsat8_list.append(sample8) \n",
    "\n",
    "l5_extract = pd.concat(landsat5_list)\n",
    "l7_extract = pd.concat(landsat7_list)\n",
    "l8_extract = pd.concat(landsat8_list)\n",
    "\n",
    "landsat_extract = pd.concat([l5_extract,l7_extract,l8_extract])\n",
    "\n",
    "landsat_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd659688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yearly:\n",
    "years_l5 = range(2000, 2012)\n",
    "years_l7 = range(2012, 2013)\n",
    "years_l8 = range(2013, 2021)\n",
    "\n",
    "landsat5_list = []\n",
    "for i in range(len(years_l5)):\n",
    "    ls5_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(yearlist_5.get(i))))\n",
    "    sample5 = ls5_x[ls5_x['Year'] == years_l5[i]]\n",
    "    landsat5_list.append(sample5) \n",
    "    \n",
    "landsat7_list = []\n",
    "for i in range(len(years_l7)):\n",
    "    ls7_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(yearlist_7.get(i))))\n",
    "    sample7 = ls7_x[ls7_x['Year'] == years_l7[i]]\n",
    "    landsat7_list.append(sample7) \n",
    "    \n",
    "landsat8_list = []\n",
    "for i in range(len(years_l8)):\n",
    "    ls8_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(yearlist_8.get(i))))\n",
    "    sample8 = ls8_x[ls8_x['Year'] == years_l8[i]]\n",
    "    landsat8_list.append(sample8) \n",
    "\n",
    "l5_extract = pd.concat(landsat5_list)\n",
    "l7_extract = pd.concat(landsat7_list)\n",
    "l8_extract = pd.concat(landsat8_list)\n",
    "\n",
    "year_extract = pd.concat([l5_extract,l7_extract,l8_extract])\n",
    "\n",
    "year_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcec489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Peak\n",
    "years_l5 = range(2000, 2012)\n",
    "years_l7 = range(2012, 2013)\n",
    "years_l8 = range(2013, 2021)\n",
    "\n",
    "landsat5_list = []\n",
    "for i in range(len(years_l5)):\n",
    "    ls5_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(peaklist_5.get(i))))\n",
    "    sample5 = ls5_x[ls5_x['Year'] == years_l5[i]]\n",
    "    landsat5_list.append(sample5) \n",
    "    \n",
    "landsat7_list = []\n",
    "for i in range(len(years_l7)):\n",
    "    ls7_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(peaklist_7.get(i))))\n",
    "    sample7 = ls7_x[ls7_x['Year'] == years_l7[i]]\n",
    "    landsat7_list.append(sample7) \n",
    "    \n",
    "landsat8_list = []\n",
    "for i in range(len(years_l8)):\n",
    "    ls8_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(peaklist_8.get(i))))\n",
    "    sample8 = ls8_x[ls8_x['Year'] == years_l8[i]]\n",
    "    landsat8_list.append(sample8) \n",
    "\n",
    "l5_extract = pd.concat(landsat5_list)\n",
    "l7_extract = pd.concat(landsat7_list)\n",
    "l8_extract = pd.concat(landsat8_list)\n",
    "\n",
    "peak_extract = pd.concat([l5_extract,l7_extract,l8_extract])\n",
    "\n",
    "peak_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9d7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daymet for loop and elevation\n",
    "years_dm = range(2000, 2021)\n",
    "\n",
    "daymet_list = []\n",
    "for i in range(len(years_dm)):\n",
    "    dm_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(dm_list.get(i))))\n",
    "    sampledm = dm_x[dm_x['Year'] == years_dm[i]]\n",
    "    daymet_list.append(sampledm) \n",
    "    \n",
    "daymet_extract = pd.concat(daymet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daymet peak time\n",
    "years_dm = range(2000, 2021)\n",
    "\n",
    "daymet_list = []\n",
    "for i in range(len(years_dm)):\n",
    "    dm_x = geemap.ee_to_pandas(rasterExtraction(ee.Image(peakdm_list.get(i))))\n",
    "    sampledm = dm_x[dm_x['Year'] == years_dm[i]]\n",
    "    daymet_list.append(sampledm) \n",
    "    \n",
    "peakdaymet_extract = pd.concat(daymet_list)\n",
    "\n",
    "peakdaymet_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2899a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final steps - extra rows in merge?\n",
    "\n",
    "#MayOct and elevation\n",
    "dfx = pd.merge(landsat_extract, dem_vals, how = 'left')\n",
    "\n",
    "#dfx and AugOct\n",
    "peak_extract.rename(\n",
    "    columns={\n",
    "        'SR_B1':'SR_B1_peak','SR_B2':'SR_B2_peak','SR_B3':'SR_B3_peak','SR_B4':'SR_B4_peak', 'SR_B5':'SR_B5_peak',\n",
    "        'SR_B6':'SR_B6_peak', 'SR_B7':'SR_B7_peak', 'flats':'flats_peak'\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "dfx1 = pd.merge(dfx, peak_extract, on = ['liveMass', 'Transect', 'locationID', 'Year'], how='outer',\n",
    "                suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')\n",
    "\n",
    "#dfx1 and year_extract\n",
    "\n",
    "year_extract.rename(\n",
    "    columns={\n",
    "        'SR_B1':'SR_B1_year','SR_B2':'SR_B2_year','SR_B3':'SR_B3_year','SR_B4':'SR_B4_year', 'SR_B5':'SR_B5_year',\n",
    "        'SR_B6':'SR_B6_year', 'SR_B7':'SR_B7_year', 'flats':'flats_year'\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "dfx2 = pd.merge(dfx1, year_extract, on = ['liveMass', 'Transect', 'locationID', 'Year'], how='outer',\n",
    "                suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')\n",
    "\n",
    "\n",
    "#dfx2 and daymet mayoct\n",
    "dfx3 = pd.merge(dfx2, daymet_extract, on = ['liveMass', 'Transect', 'locationID', 'Year'], how='right')\n",
    "\n",
    "#dfx3 and daymet peak\n",
    "peakdaymet_extract.rename(\n",
    "    columns={\n",
    "        'swe':'swe_peak','tmax':'tmax_peak','tmin':'tmin_peak','srad':'srad_peak', 'vp':'vp_peak',\n",
    "        'prcp':'prcp_peak', 'dayl':'dayl_peak'\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "df = pd.merge(dfx3, peakdaymet_extract, on = ['liveMass', 'Transect', 'locationID', 'Year'], how='right',\n",
    "              suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bands and indices\n",
    "df['Sensor'] = np.where(df['Year']<2013, 'Landsat 5', 'Landsat 8') ##make sure no other sensors are being used\n",
    "\n",
    "df.loc[df['Year'] == 2012, 'Sensor'] = 'Landsat 7'\n",
    "\n",
    "df['ndvi'] = np.where(df['Sensor'] == 'Landsat 8', (df['SR_B5']-df['SR_B4'])/(df['SR_B5']+df['SR_B4']), \\\n",
    "                      (df['SR_B4']-df['SR_B3'])/(df['SR_B4']+df['SR_B3'])) \n",
    "##ndvi conditional based on whether sensor is Landsat-5 or 8\n",
    "\n",
    "df['Blue_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B2'], df['SR_B1'])\n",
    "df['Green_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B3'], df['SR_B2'])\n",
    "df['Red_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B4'], df['SR_B3'])\n",
    "df['NIR_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B5'], df['SR_B4'])\n",
    "df['SWIR1_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B6'], df['SR_B5'])\n",
    "df['SWIR2_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B7'], df['SR_B7'])\n",
    "\n",
    "##Variables from Byrd et al. 2018 (make sure calculations are accurate):\n",
    "df['savi'] = ((df['NIR_band']-df['Red_band'])*1.5)/(df['NIR_band']+df['Red_band']+0.5)\n",
    "df['wdrvi5'] = (0.5*df['NIR_band']-df['Red_band'])/(0.5*df['NIR_band']+df['Red_band'])\n",
    "df['nd_r_g'] = (df['Red_band']-df['Green_band'])/(df['Red_band']+df['Green_band'])\n",
    "df['nd_g_b'] = (df['Green_band']-df['Blue_band'])/(df['Green_band']+df['Blue_band'])\n",
    "df['nd_swir2_nir'] = (df['SWIR2_band']-df['NIR_band'])/(df['SWIR2_band']+df['NIR_band'])\n",
    "df['nd_swir2_r'] = (df['SWIR2_band']-df['Red_band'])/(df['SWIR2_band']+df['Red_band'])\n",
    "\n",
    "display(df)\n",
    "\n",
    "##EXPORT\n",
    "out_dir = os.path.expanduser('~/Downloads')\n",
    "out_csv = os.path.join(out_dir, 'df_mayoct.csv')\n",
    "# df.to_csv(out_csv, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ndvi_year'] = np.where(df['Sensor'] == 'Landsat 8', (df['SR_B5_year']-df['SR_B4_year'])/(df['SR_B5_year']+df['SR_B4_year']), \\\n",
    "                      (df['SR_B4_year']-df['SR_B3_year'])/(df['SR_B4_year']+df['SR_B3_year'])) \n",
    "##ndvi conditional based on whether sensor is Landsat-5 or 8\n",
    "\n",
    "df['Blue_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B2_year'], df['SR_B1_year'])\n",
    "df['Green_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B3_year'], df['SR_B2_year'])\n",
    "df['Red_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B4_year'], df['SR_B3_year'])\n",
    "df['NIR_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B5_year'], df['SR_B4_year'])\n",
    "df['SWIR1_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B6_year'], df['SR_B5_year'])\n",
    "df['SWIR2_band_year'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B7_year'], df['SR_B7_year'])\n",
    "\n",
    "##Variables from Byrd et al. 2018 (make sure calculations are accurate):\n",
    "df['savi_year'] = ((df['NIR_band_year']-df['Red_band_year'])*1.5)/(df['NIR_band_year']+df['Red_band_year']+0.5)\n",
    "df['wdrvi5_year'] = (0.5*df['NIR_band_year']-df['Red_band_year'])/(0.5*df['NIR_band_year']+df['Red_band_year'])\n",
    "df['nd_r_g_year'] = (df['Red_band_year']-df['Green_band_year'])/(df['Red_band_year']+df['Green_band_year'])\n",
    "df['nd_g_b_year'] = (df['Green_band_year']-df['Blue_band_year'])/(df['Green_band_year']+df['Blue_band_year'])\n",
    "df['nd_swir2_nir_year'] = (df['SWIR2_band_year']-df['NIR_band_year'])/(df['SWIR2_band_year']+df['NIR_band_year'])\n",
    "df['nd_swir2_r_year'] = (df['SWIR2_band_year']-df['Red_band_year'])/(df['SWIR2_band_year']+df['Red_band_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6237e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ndvi_peak'] = np.where(df['Sensor'] == 'Landsat 8', (df['SR_B5_peak']-df['SR_B4_peak'])/(df['SR_B5_peak']+df['SR_B4_peak']), \\\n",
    "                      (df['SR_B4_peak']-df['SR_B3_peak'])/(df['SR_B4_peak']+df['SR_B3_peak'])) \n",
    "##ndvi conditional based on whether sensor is Landsat-5 or 8\n",
    "\n",
    "df['Blue_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B2_peak'], df['SR_B1_peak'])\n",
    "df['Green_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B3_peak'], df['SR_B2_peak'])\n",
    "df['Red_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B4_peak'], df['SR_B3_peak'])\n",
    "df['NIR_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B5_peak'], df['SR_B4_peak'])\n",
    "df['SWIR1_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B6_peak'], df['SR_B5_peak'])\n",
    "df['SWIR2_band_peak'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B7_peak'], df['SR_B7_peak'])\n",
    "\n",
    "##Variables from Byrd et al. 2018 (make sure calculations are accurate):\n",
    "df['savi_peak'] = ((df['NIR_band_peak']-df['Red_band_peak'])*1.5)/(df['NIR_band_peak']+df['Red_band_peak']+0.5)\n",
    "df['wdrvi5_peak'] = (0.5*df['NIR_band_peak']-df['Red_band_peak'])/(0.5*df['NIR_band_peak']+df['Red_band_peak'])\n",
    "df['nd_r_g_peak'] = (df['Red_band_peak']-df['Green_band_peak'])/(df['Red_band_peak']+df['Green_band_peak'])\n",
    "df['nd_g_b_peak'] = (df['Green_band_peak']-df['Blue_band_peak'])/(df['Green_band_peak']+df['Blue_band_peak'])\n",
    "df['nd_swir2_nir_peak'] = (df['SWIR2_band_peak']-df['NIR_band_peak'])/(df['SWIR2_band_peak']+df['NIR_band_peak'])\n",
    "df['nd_swir2_r_peak'] = (df['SWIR2_band_peak']-df['Red_band_peak'])/(df['SWIR2_band_peak']+df['Red_band_peak'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bands and indices\n",
    "df['Sensor'] = np.where(df['Year']<2013, 'Landsat 5', 'Landsat 8') ##make sure no other sensors are being used\n",
    "\n",
    "df.loc[df['Year'] == 2012, 'Sensor'] = 'Landsat 7'\n",
    "\n",
    "df['ndvi'] = np.where(df['Sensor'] == 'Landsat 8', (df['SR_B5']-df['SR_B4'])/(df['SR_B5']+df['SR_B4']), \\\n",
    "                      (df['SR_B4']-df['SR_B3'])/(df['SR_B4']+df['SR_B3'])) \n",
    "##ndvi conditional based on whether sensor is Landsat-5 or 8\n",
    "\n",
    "df['Blue_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B2'], df['SR_B1'])\n",
    "df['Green_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B3'], df['SR_B2'])\n",
    "df['Red_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B4'], df['SR_B3'])\n",
    "df['NIR_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B5'], df['SR_B4'])\n",
    "df['SWIR1_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B6'], df['SR_B5'])\n",
    "df['SWIR2_band'] = np.where(df['Sensor'] == 'Landsat 8', df['SR_B7'], df['SR_B7'])\n",
    "\n",
    "##Variables from Byrd et al. 2018 (make sure calculations are accurate):\n",
    "df['savi'] = ((df['NIR_band']-df['Red_band'])*1.5)/(df['NIR_band']+df['Red_band']+0.5)\n",
    "df['wdrvi5'] = (0.5*df['NIR_band']-df['Red_band'])/(0.5*df['NIR_band']+df['Red_band'])\n",
    "df['nd_r_g'] = (df['Red_band']-df['Green_band'])/(df['Red_band']+df['Green_band'])\n",
    "df['nd_g_b'] = (df['Green_band']-df['Blue_band'])/(df['Green_band']+df['Blue_band'])\n",
    "df['nd_swir2_nir'] = (df['SWIR2_band']-df['NIR_band'])/(df['SWIR2_band']+df['NIR_band'])\n",
    "df['nd_swir2_r'] = (df['SWIR2_band']-df['Red_band'])/(df['SWIR2_band']+df['Red_band'])\n",
    "\n",
    "display(df)\n",
    "\n",
    "##EXPORT\n",
    "out_dir = os.path.expanduser('~/Downloads')\n",
    "out_csv = os.path.join(out_dir, 'va_min.csv')\n",
    "# df.to_csv(out_csv, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Next step: ML\n",
    "df = df[df['Red_band'].notna()]\n",
    "df = df[df['SR_B4_peak'].notna()]\n",
    "df = df[df['SR_B4_year'].notna()]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d6c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#:)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
